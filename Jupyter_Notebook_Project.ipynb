{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a66af73",
   "metadata": {},
   "source": [
    "# Apple Music Data Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210cdf1f",
   "metadata": {},
   "source": [
    "### Structure for this Project:\n",
    "### Section 1: Introduction\n",
    "### Section 2: Data Extraction\n",
    "### Section 3: Understanding the Data(Importing Data)\n",
    "### Section 4: Analyzing Play Activity\n",
    "### Section 5: Restructuring Library Tracks Related Information\n",
    "### Section 6: Restructuring Likes and Dislikes Dataframe\n",
    "### Section 7: Analyzing Library Activity DataFrame\n",
    "### Section 8: Building a Data Structure for Tracks\n",
    "### Section 9: Checking for Duplicates\n",
    "### Section 10: Merging Track Instances with Play Activity DataFrame\n",
    "### Section 11: Data Visualization\n",
    "####     Section 11.1: Listening Trends\n",
    "####     Section 11.2: Listening Duration\n",
    "####     Section 11.3: Ranking\n",
    "####     Section 11.4: Listening Habits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35a4574",
   "metadata": {},
   "source": [
    "### Section 1: Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0886bc5f",
   "metadata": {},
   "source": [
    "#### There is no denying that the way we consume music has changed over the past few decades. Earlier, albums were sold in cassettes and compact disks(CDs) which everyone would buy from designated sellers. Now, with the rise of social media, things have definitely changed. Fewer people bother buying CDs from their favourite artists and instead turn to platforms like SoundCloud, Spotify, and Apple Music to listen to their favourite music. You wonder how do these record companies manage to hire music artists for record amounts and the answer lies in an increased dependency on Data Science. Data Science helps music companies to closely analyze trends and predict what their next big hit would be. They can easily take advantage of the vast amounts of data available to see the trajectory of the kind of music that appeals to a large audience and nudge their artists to produce such music."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8188605f",
   "metadata": {},
   "source": [
    "#### What's the first thing that comes to your mind when your friend says that he has been hooked to a new song? Chances are, you think about a particular artist or band, maybe the chorus or the background music which really makes a song stand out. The reality is that big music companies have directed your attention towards a certain type of music- through years and years of data analysis- so that you are used to the kind of music they produce and more likely to listen. It's not a long stretch to say that music industries have designed their business model around making you accustomed to a certain type of music. The type of music is determined by music analytics and its potential to rise and compete with music produced by other music companies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5262f1ae",
   "metadata": {},
   "source": [
    "#### In conclusion, producing the next big hit isn’t about raw talent anymore; it’s about taking years of data into consideration and then choosing a song whose genre and lyrics have relevance to the time of release, which will cause it to go well with listeners. Music companies don’t have to depend on one artist either; in recent years, we’ve seen songs by previously unknown singers to become instant hits.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f69a923",
   "metadata": {},
   "source": [
    "### Section 2: Data Extraction:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252fa495",
   "metadata": {},
   "source": [
    "#### Thanks to the European Union's General Data Protection Regulation (GDPR) requirements which were established in 2018, users have the right to access their personal data which includes information like basic identity information, webdata like location, IP addresses, cookie data. You can now request an electronic copy of your personal data, free of charge, upon request and can even inquire about how your data is used, stored, processed or transferred to other organizations. When I found out that I could request an archive with all my usage data since 2021, I requested a copy of my data following the required steps:\n",
    "\n",
    "1. Head to Apple’s Data and Privacy log in page\n",
    "2. Log in with the Apple ID for which you’d like to download data\n",
    "3. Under Get a copy of your data, click Get Started\n",
    "<img width=\"1157\" alt=\"Screenshot 2022-10-23 at 1 31 46 AM\" src=\"https://user-images.githubusercontent.com/116476247/197375971-c6eff7d3-d335-418e-a644-bbce028f237f.png\">\n",
    "4. Select the data you’d like, 'App Store, Itunes Store, Apple Books and Apple Music'\n",
    "<img width=\"1055\" alt=\"Screenshot 2022-10-23 at 1 31 54 AM\" src=\"https://user-images.githubusercontent.com/116476247/197375987-cf6f289a-ac05-4f0a-98b9-a2505392503b.png\">\n",
    "5. Choose the maximum default file size and click on Complete Request\n",
    "<img width=\"705\" alt=\"Screenshot 2022-10-23 at 1 32 00 AM\" src=\"https://user-images.githubusercontent.com/116476247/197375990-0153f2a4-2a66-4eac-83e8-eb9c69abe0b3.png\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8a9209",
   "metadata": {},
   "source": [
    "### Section 3: Understanding the Data (Importing Data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ace3ece",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###import statements\n",
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "import plotly.offline as pyo\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as pex\n",
    "from plotly.subplots import make_subplots\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a1ae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing relevant json and csv files for analysis\n",
    "\n",
    "### relevant for understanding overall play activity on Apple Music\n",
    "play_activity_dataframe = pd.read_csv(\"/Users/khushgarg/Desktop/Apple Music Play Activity.csv\")\n",
    "\n",
    "### relevant for getting track related information in the library\n",
    "library_tracks_information_dataframe = pd.read_json(\"/Users/khushgarg/Desktop/Apple Music Library Tracks.json\")\n",
    "\n",
    "### songs liked and disliked\n",
    "likes_dislikes_dataframe = pd.read_csv(\"/Users/khushgarg/Desktop/Apple Music Likes and Dislikes.csv\")\n",
    "\n",
    "### general activity in your library\n",
    "library_activity_dataframe = pd.read_json(\"/Users/khushgarg/Desktop/Apple Music Library Activity.json\")\n",
    "\n",
    "### identifier information for particular tracks\n",
    "identifier_information_dataframe = pd.read_json(\"/Users/khushgarg/Desktop/Identifier Information.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642a537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_activity_dataframe.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88584b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "play_activity_dataframe.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94238d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "library_tracks_information_dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d07f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "library_tracks_information_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f14759",
   "metadata": {},
   "outputs": [],
   "source": [
    "likes_dislikes_dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c59bd0a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "likes_dislikes_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2014823f",
   "metadata": {},
   "outputs": [],
   "source": [
    "library_activity_dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29874b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "library_activity_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15490997",
   "metadata": {},
   "outputs": [],
   "source": [
    "identifier_information_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fb3323",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of the playactivity dataframe: \", play_activity_dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700c86c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Shape of the library tracks related information dataframe: \", library_tracks_information_dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29ae144",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of the library activity dataframe:\", library_activity_dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6161267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of the likes/dislikes dataframe:\", likes_dislikes_dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10db6905",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of the list of songs that have ID:\", identifier_information_dataframe.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c469834d",
   "metadata": {},
   "source": [
    "### Section 4: Analysing Play Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e9bd42",
   "metadata": {},
   "source": [
    "#### Can I build a single dataframe that would allow me to build statistics and identify trends on the type of music I listen to, at what moment in time, if the trends change from month to month, how I usually find new tracks ? The dataframe containing the most information about playing activity is Apple Music Play Activity. Hence, we use this dataframe as our base and enrich this dataframe with information obtained from other dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a659918",
   "metadata": {},
   "source": [
    "#### We use the iloc() function to retrieve and inspect any specific row of our dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641b84ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_activity_dataframe.iloc[1900]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e2fb58",
   "metadata": {},
   "source": [
    "#### At first glance, the following columns look interesting:\n",
    "1. End Reason Type: To spot whether a track was skipped or played till the end of the track\n",
    "2. Feature Name: To spot how the track was found \n",
    "3. Artist Name and Song Name: To fetch information about a particular song\n",
    "4. Event Start Timestamp: To identify when the track was listened to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fda1dbe",
   "metadata": {},
   "source": [
    "#### We use the unique() function to find the unique values from each column that we are interested in inspecting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060742c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_activity_dataframe[\"End Reason Type\"].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d7c0b2",
   "metadata": {},
   "source": [
    "#### So, for any given song, we can use \"End reason Type\" to identify:\n",
    "1. Whether a song was skipped or listened partially(TRACK_SKIPPED_FORWARDS, TRACK_SKIPPED_BACKWARDS, SCRUB_BEGIN)\n",
    "2. Listened to entirely(NATURAL_END_OF_TRACK)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376d6147",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_activity_dataframe[\"Event Type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc7ed35",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_activity_dataframe[\"Feature Name\"].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6393a3f0",
   "metadata": {},
   "source": [
    "#### We can use this column to filter and find the origin of the song. I categorised them into four categories:\n",
    "1. Search (this category includes songs that I have browsed manually on the app)\n",
    "2. Library (this category includes songs that I have listened through my own playlists)\n",
    "3. Radio (this category includes songs that I have listened through the Listen Now feature on Apple Music which usually plays my favourite songs and provides me with personalized recommendations)\n",
    "4. Other(this category includes songs played using Siri, Alexa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b759dd",
   "metadata": {},
   "source": [
    "### Step 1: Cleaning and restructuring the dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95de3c1a",
   "metadata": {},
   "source": [
    "#### I spent some time cleaning up this dataframe to get a simplified dataframe which is easy to work with.  Not all columns in this dataframe are useful for data analysis; hence, the drop() function is used to remove any unwanted columns. We get rid of the following columns: \n",
    "\n",
    "1. Apple ID Number\n",
    "2. Apple Music Subscription\n",
    "3. Build Version\n",
    "4. Client IP Address\n",
    "5. Device Identifier\n",
    "6. End Position in Milliseconds\n",
    "7. Event Reason Hint Type\n",
    "8. Event Received Timestamp\n",
    "9. Item Type\n",
    "10. Media Type\n",
    "11. Metrics Bucket Id\n",
    "12. Metrics Client Id\n",
    "13. Milliseconds Since Play\n",
    "14. Provided Audio Bit Depth                                                        \n",
    "15. Provided Audio Channel                                                       \n",
    "16. Provided Audio Sample Rate                                                      \n",
    "17. Provided Bit Rate                                                           \n",
    "18. Provided Codec                                                                   \n",
    "19. Provided Playback Format                                                     \n",
    "20. Session Is Shared                                                              \n",
    "21. Shared Activity Devices-Current                                                  \n",
    "22. Shared Activity Devices-Max   \n",
    "23. Source Type\n",
    "24. Start Position in Milliseconds\n",
    "25. Store Country Name\n",
    "26. User’s Audio Quality                                                    \n",
    "27. User’s Playback Format                                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6a3ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_dropped = ['Apple ID Number', 'Apple Music Subscription',\n",
    "       'Build Version', 'Client IP Address', 'Device Identifier',\n",
    "       'End Position In Milliseconds', 'Event Reason Hint Type',\n",
    "       'Event Received Timestamp', 'Item Type','Media Type', 'Metrics Bucket Id', 'Metrics Client Id',\n",
    "       'Milliseconds Since Play', 'Provided Audio Bit Depth', 'Provided Audio Channel',\n",
    "       'Provided Audio Sample Rate', 'Provided Bit Rate', 'Provided Codec',\n",
    "       'Provided Playback Format', 'Session Is Shared',\n",
    "       'Shared Activity Devices-Current', 'Shared Activity Devices-Max', 'Source Type', 'Start Position In Milliseconds',\n",
    "       'Store Front Name', 'User’s Audio Quality', 'User’s Playback Format']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b804177",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_activity_new_dataframe = play_activity_dataframe.drop(columns_dropped, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec4ad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_activity_new_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dac9b4b",
   "metadata": {},
   "source": [
    "#### We notice that this dataframe does not contain any id number which can be used to match each row of this dataframe with information from other dataframes. Hence, we will rename the columns: Artist Name and Song Name and use these two columns for merging information from other dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1345c42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_activity_new_dataframe.rename({\"Artist Name\" : \"Artist\", \"Song Name\": \"Song Title\"}, inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0467d5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_activity_new_dataframe.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ca0ca5",
   "metadata": {},
   "source": [
    "#### Now, we will add columns to this dataset:\n",
    "1. Extract year, month, day of month, day of week, and hour of the day for each track. We use the column \"Event Start Timestamp\" as a reference and when it is not available, we use the column \"Event End Timestamp\" as our reference point. Hence, this timestamp column is without any missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e086ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add time related columns\n",
    "### to_datetime function from the pandas module converts object datatype to a timestamp (datetime64[ns])\n",
    "\n",
    "# Defining reference activity time column\n",
    "play_activity_new_dataframe['Play Activity date-time'] = pd.to_datetime(play_activity_new_dataframe['Event Start Timestamp'])\n",
    "play_activity_new_dataframe['Play Activity date-time'].fillna(pd.to_datetime(play_activity_new_dataframe['Event End Timestamp']), inplace=True)\n",
    "\n",
    "### here, we use .dt as an accessor object for performing datetime related actions\n",
    "# Add broken down date into year, month, day of the month, day of the week\n",
    "play_activity_new_dataframe['Play Year'] = play_activity_new_dataframe['Play Activity date-time'].dt.year\n",
    "play_activity_new_dataframe['Play Month'] = play_activity_new_dataframe['Play Activity date-time'].dt.month\n",
    "play_activity_new_dataframe['Play Date'] = play_activity_new_dataframe['Play Activity date-time'].dt.day\n",
    "play_activity_new_dataframe['Play Day of the Week'] = play_activity_new_dataframe['Play Activity date-time'].dt.day_name()\n",
    "\n",
    "# Add hour of the day in UTC and in local time\n",
    "\n",
    "play_activity_new_dataframe['Play Hour in UTC']= play_activity_new_dataframe['Play Activity date-time'].dt.hour\n",
    "play_activity_new_dataframe['Play Hour in Local Time']= play_activity_new_dataframe['Play Hour in UTC'] + play_activity_new_dataframe['UTC Offset In Seconds']/3600\n",
    "play_activity_new_dataframe['Play Hour in Local Time'] = play_activity_new_dataframe['Play Hour in Local Time'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769ca317",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_activity_new_dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6bf752",
   "metadata": {},
   "source": [
    "#### 2. Now, we will add a column that would indicate partial vs complete listening of the song. If the \"End Reason Type\" for a particular song is Natural_End_Of_Track and if the play duration is above the media duration in milliseconds, we consider the track to be listened to completely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f75666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_listening (dataframe):\n",
    "    if dataframe[\"End Reason Type\"] == 'NATURAL_END_OF_TRACK':\n",
    "        return True\n",
    "    else:\n",
    "        if dataframe['Play Duration Milliseconds'] >= dataframe[\"Media Duration In Milliseconds\"]:\n",
    "            return True\n",
    "        else: \n",
    "            return False\n",
    "play_activity_new_dataframe[\"Play Status\"] = play_activity_new_dataframe.apply(partial_listening, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a73df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This shows whether a particular song was listened to completely or not using the Play Status column as an indicator\n",
    "play_activity_new_dataframe[[\"Song Title\", \"Play Status\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371c7125",
   "metadata": {},
   "source": [
    "#### 3. Now, we will add a column that indicates the origin of the song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5924f14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add track origin column\n",
    "\n",
    "def track_origin(origin):\n",
    "    if str(origin) != 'nan':\n",
    "        origin_simplified = str(origin).split('/')[0].strip()\n",
    "        if origin_simplified == 'search' or origin_simplified =='browse':\n",
    "            return 'search'\n",
    "        elif origin_simplified == 'library':\n",
    "            return 'library'\n",
    "        elif origin_simplified == 'listen_now' or origin_simplified == 'radio':\n",
    "            return 'radio'\n",
    "        else:\n",
    "            return 'other'\n",
    "    else: \n",
    "        return 'other'\n",
    "    \n",
    "\n",
    "# we add a column with the origin of the song, and remove the column Feature Name\n",
    "play_activity_new_dataframe['Track origin'] = play_activity_new_dataframe['Feature Name'].apply(track_origin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c7ddb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_activity_new_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1c52b2",
   "metadata": {},
   "source": [
    "#### 4. Now, we will add the play duration column. We use appropriate nesting to handle two specific types of cases: songs with no NA values for both Start and End Timestamps and songs with missing values in one of these two columns. To handle the latter, we make use of the Play Status column that we just added to the dataframe. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1780573e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We look at the number of NA values in our dataset \n",
    "import numpy as np\n",
    "np.count_nonzero(play_activity_new_dataframe.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d297dba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add play duration column\n",
    "\n",
    "def play_duration(dataframe):\n",
    "    end = pd.to_datetime(dataframe['Event End Timestamp'])\n",
    "    start = pd.to_datetime(dataframe['Event Start Timestamp'])\n",
    "    if str(end) != 'NaT' and str(start) != 'NaT':  ### For cases with timestamps with no NA values for both End and Start Timestamps, we use AND operator\n",
    "        if end.day == start.day:\n",
    "            difference = end - start \n",
    "            duration = difference.total_seconds() / 60  ## using the _total_seconds() from the timestamp to obtain duration in minutes\n",
    "        else:\n",
    "            duration = dataframe['Media Duration In Milliseconds'] / 60000  ## 1 minute = 60 seconds = 60000 milliseconds\n",
    "    else:  ###For cases with NA values in either End Timestamp or Start TimeStamp, we use the PlayStatus column \n",
    "        if dataframe['Play Status'] is False:\n",
    "            if type(dataframe['Play Duration Milliseconds']) == float:  ###To handle NA values in the Play Duration column (Example: Look at Index 1)\n",
    "                duration = dataframe['Media Duration In Milliseconds'] / 60000\n",
    "            else: ### For the song tracks with Play Status = False and NA values in the Media Duration Column\n",
    "                duration = dataframe['Play Duration Milliseconds'] / 60000       \n",
    "        else:\n",
    "            duration = dataframe['Media Duration In Milliseconds'] / 60000\n",
    "    return duration\n",
    "\n",
    "play_activity_new_dataframe['Play duration in minutes'] = play_activity_new_dataframe.apply(play_duration, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2743914",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### For reference, we can see how rows with NA values are handled\n",
    "play_activity_new_dataframe[play_activity_new_dataframe.isna().values]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2458e06",
   "metadata": {},
   "source": [
    "#### 5. Remove Outliers with listening duration above 99% percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d2537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### We remove outliers by saying that if a value if above the 99th percentile,\n",
    "# we drop it, and replace it by the duration of the media\n",
    "\n",
    "def remove_outliers(dataframe):\n",
    "    if dataframe['Play duration in minutes'] <= percentile:\n",
    "        return dataframe['Play duration in minutes']\n",
    "    else:\n",
    "        return dataframe['Media Duration In Milliseconds'] / 60000\n",
    "\n",
    "\n",
    "\n",
    "percentile = play_activity_new_dataframe['Play duration in minutes'].quantile(0.99)\n",
    "play_activity_new_dataframe['Play duration in minutes'] = play_activity_new_dataframe.apply(remove_outliers, axis=1)\n",
    "\n",
    "\n",
    "#we can then remove the columns we do not need anymore!\n",
    "play_activity_new_dataframe = play_activity_new_dataframe.drop(['Event End Timestamp', 'Event Start Timestamp', 'UTC Offset In Seconds',\n",
    "                                'Play Duration Milliseconds', 'Media Duration In Milliseconds'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f076812b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "play_activity_new_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd960ba",
   "metadata": {},
   "source": [
    "### Section 5: Restructuring Library Tracks Related Information Dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3a7377",
   "metadata": {},
   "source": [
    "Here, we look at how any specific row of this dataframe looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23011f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "library_tracks_information_dataframe.iloc[1010]\n",
    "                                         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fb129d",
   "metadata": {},
   "source": [
    "Here, we look at any missing titles in the dataframe. We find that there are no missing titles in this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0512240",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "library_tracks_information_dataframe[library_tracks_information_dataframe['Title'] == \"NaN\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b8cfce",
   "metadata": {},
   "source": [
    "We drop the following columns from the dataframe:\n",
    "1. Content Type\n",
    "2. Sort Name\n",
    "3. Sort Artist\n",
    "4. Is Part of Compilation \n",
    "5. Sort Album\n",
    "6. Album Artist\n",
    "7. Track Number on Album\n",
    "8. Track Count on Album\n",
    "9. Disc Number of Album\n",
    "10. Disc Count of Album\n",
    "11. Date Added To iCloud Music Library\n",
    "12. Last Modified Date\n",
    "13. Is Purchased\n",
    "14. Audio File Extension \n",
    "15. Is Checked\n",
    "16. Copyright\n",
    "17. Playlist Only Track                                                                  \n",
    "18. Grouping                                                                            \n",
    "19. Comments                                                                            \n",
    "20. Beats Per Minute                                                                    \n",
    "21. Rating                                                                             \n",
    "22. Album Rating                                                                        \n",
    "23. Remember Playback Position                                                          \n",
    "24. Album Like Rating                                                                   \n",
    "25. Album Rating Method                                                                 \n",
    "26. Work Name                                                                           \n",
    "27. Movement Name                                                                       \n",
    "28. Movement Number                                                                     \n",
    "29. Movement Count                                                                      \n",
    "30. Display Work Name                                                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e698e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['Content Type', 'Sort Name',\n",
    "'Sort Artist', 'Is Part of Compilation', 'Sort Album',\n",
    "'Album Artist', 'Track Number On Album',\n",
    "'Track Count On Album', 'Disc Number Of Album', 'Disc Count Of Album',\n",
    "'Date Added To iCloud Music Library', 'Last Modified Date',\n",
    " 'Is Purchased', 'Audio File Extension',\n",
    "'Is Checked', 'Copyright', 'Playlist Only Track','Grouping', 'Comments', \n",
    "'Beats Per Minute', 'Album Rating', 'Remember Playback Position', \n",
    "'Album Like Rating', 'Album Rating Method', 'Work Name', 'Rating',\n",
    "'Movement Name', 'Movement Number', 'Movement Count',\n",
    "'Display Work Name']\n",
    "\n",
    "library_tracks_information_dataframe = library_tracks_information_dataframe.drop(columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcb5956",
   "metadata": {},
   "outputs": [],
   "source": [
    "library_tracks_information_dataframe.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba68668e",
   "metadata": {},
   "source": [
    "This displays our resultant dataframe after we remove the unnecessary columns for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41463334",
   "metadata": {},
   "outputs": [],
   "source": [
    "library_tracks_information_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81a3137",
   "metadata": {},
   "source": [
    "### Section 6: Restructuring Likes and Dislikes Dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad1ae6b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We construct a column title and a column name from the existing Item Description column\n",
    "\n",
    "likes_dislikes_dataframe['Title'] = likes_dislikes_dataframe['Item Description'].str.split(' -').str.get(1).str.strip()\n",
    "likes_dislikes_dataframe['Artist'] = likes_dislikes_dataframe['Item Description'].str.split(' - ').str.get(0).str.strip()\n",
    "likes_dislikes_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be757d1",
   "metadata": {},
   "source": [
    "### Section 7: Analyzing Library Activity Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d43c9af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "library_activity_dataframe.iloc[108]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433aff50",
   "metadata": {},
   "source": [
    "#### What are the type of transactions performed in my library?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39a1955",
   "metadata": {},
   "outputs": [],
   "source": [
    "library_activity_dataframe['Transaction Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5070d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### UpdateItems occurs the most\n",
    "library_activity_dataframe[library_activity_dataframe['Transaction Type'] == 'updateItems']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64a24de",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Looking at the tracks column in detail\n",
    "library_activity_dataframe[library_activity_dataframe['Transaction Type'] == 'updateItems']['Tracks'].iloc[20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6c8ae5",
   "metadata": {},
   "source": [
    "#### We see that the last played date is updated. We also see that there is one column which contains the UserAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47212401",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "library_activity_dataframe['UserAgent'].value_counts(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46df945",
   "metadata": {},
   "source": [
    "#### There are three main categories :\n",
    "\n",
    "1. Internal Software\n",
    "2. AMPLibraryAgent\n",
    "3. itunescloudd (from an iPhone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c46ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''we add columns to extract year, month, day of the month and day of the week from the transaction date\n",
    "'''\n",
    "library_activity_dataframe['Transaction Simplified Date'] = pd.to_datetime(library_activity_dataframe['Transaction Date'].str.split('T').str.get(0))\n",
    "library_activity_dataframe['Transaction Year'] = library_activity_dataframe['Transaction Date'].str.split('-').str.get(0)\n",
    "library_activity_dataframe['Transaction Month'] = library_activity_dataframe['Transaction Date'].str.split('-').str.get(1)\n",
    "library_activity_dataframe['Transaction DOW'] = library_activity_dataframe['Transaction Simplified Date'].dt.day_name()\n",
    "library_activity_dataframe['Transaction Agent'] = library_activity_dataframe['UserAgent'].str.split('/').str.get(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eece92f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' simplifying the values of the transaction agent'''\n",
    "\n",
    "library_activity_dataframe['Transaction Agent'] = library_activity_dataframe['Transaction Agent'].replace(to_replace =\"itunescloudd\", value =\"iPhone\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a897e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plotting the distribution of action per date and agent\n",
    "\n",
    "color = {'Internal Software':'rgb(149, 216, 64)', 'AMPLibraryAgent':'rgb(68, 1, 84)',\n",
    "         'iPhone':'rgb(220, 227, 25)'}\n",
    "\n",
    "\n",
    "graph = []\n",
    "\n",
    "\n",
    "graph.append(\n",
    "    go.Scatter(\n",
    "        name='iPhone',\n",
    "        x=library_activity_dataframe[library_activity_dataframe['Transaction Agent'] == 'iPhone']['Transaction Simplified Date'],\n",
    "        y=library_activity_dataframe[library_activity_dataframe['Transaction Agent'] == 'iPhone']['Transaction Type'],\n",
    "        showlegend=True,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=math.log(library_activity_dataframe[library_activity_dataframe['Transaction Agent'] == 'iPhone']['Transaction Type'].count()*1000),\n",
    "            color=color['iPhone'],\n",
    "            opacity=0.2,\n",
    "        ),\n",
    "    ))\n",
    "graph.append(\n",
    "    go.Scatter(\n",
    "        name='AMPLibraryAgent',\n",
    "        x=library_activity_dataframe[library_activity_dataframe['Transaction Agent'] == 'AMPLibraryAgent']['Transaction Simplified Date'],\n",
    "        y=library_activity_dataframe[library_activity_dataframe['Transaction Agent'] == 'AMPLibraryAgent']['Transaction Type'],\n",
    "        showlegend=True,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=math.log(library_activity_dataframe[library_activity_dataframe['Transaction Agent'] == 'AMPLibraryAgent']['Transaction Type'].count()*1000),\n",
    "            color=color['AMPLibraryAgent'],\n",
    "            opacity=0.5,\n",
    "        ),\n",
    "    ))\n",
    "graph.append(\n",
    "    go.Scatter(\n",
    "        name='Internal Software',\n",
    "        x=library_activity_dataframe[library_activity_dataframe['Transaction Agent'] == 'Internal Software']['Transaction Simplified Date'],\n",
    "        y=library_activity_dataframe[library_activity_dataframe['Transaction Agent'] == 'Internal Software']['Transaction Type'],\n",
    "        showlegend=True,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=math.log(library_activity_dataframe[library_activity_dataframe['Transaction Agent'] == 'Internal Software']['Transaction Type'].count()*1000),\n",
    "            color=color['Internal Software'],\n",
    "            opacity=0.5,\n",
    "        ),\n",
    "            ))\n",
    "\n",
    "\n",
    "layout = dict(title='Number of transaction per date and agent',\n",
    "                  yaxis=dict(title=\"Transaction type\"),\n",
    "                  xaxis=dict(title=\"Date\"))\n",
    "\n",
    "fig = go.Figure(data=graph, layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47691549",
   "metadata": {},
   "outputs": [],
   "source": [
    "library_activity_dataframe['Transaction Agent Model'] = library_activity_dataframe[library_activity_dataframe['Transaction Agent'] == 'iPhone']['UserAgent'].str.split('/').str.get(3).str.split(',').str.get(0)\n",
    "library_activity_dataframe['Transaction Agent Model'].dropna().unique()\n",
    "\n",
    "labels = library_activity_dataframe['Transaction Agent Model'].dropna().unique()\n",
    "values = library_activity_dataframe['Transaction Agent Model'].value_counts()\n",
    "\n",
    "fig = go.Figure(data=[go.Pie(labels=labels, values=values)])\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2bd03a",
   "metadata": {},
   "source": [
    "### Section 8: Building a data structure for Tracks: \n",
    "As we do not have a column with an unique identifier which could be used to match songs from one dataframe to another dataframe, we create a Track class instance which stores all the information for each song from all the dataframes that we have restructured. The idea is to create a new data structure named Track and for each instance, we use this Track class to update information from the various dataframes.\n",
    " \n",
    "For each input dataframe, we try to identify the rows that represents a song we already saw and for which we already have an instance. We use a similarity score between the 'Title && Artist'string combinations to know whether we have seen that song before(i.e we already have a track instance for a given item). For example, comparing 'Bad Guy && Billie Eilish' and 'Bad Guy (Radio Edit) && Billie Eilish' will return a high similarity score. We create or update track instances as needed. Additionally, for each track instance, we record in which dataframe we gathered information from (using the row index)\n",
    "\n",
    "For each artist, we track all the songs listened to with the help of a dictionary. While processing our data, we exclude songs that do not contain a Title (‘NaN’), or those we could not find a close match using ‘Title && Artist’ string combination.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6daea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SequenceMatcher is a class that is available in the difflib package which can be used to compare two input strings. \n",
    "# the .ratio() returns the similarity score (float in [0,1])\n",
    "def similarity (title1, title2):\n",
    "    return SequenceMatcher(None, title1, title2).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ac3de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class is going to help us building a reference data structure for all the tracks, \n",
    "# looking at all the information available from all the different df we have at our disposal\n",
    "\n",
    "\n",
    "class Track():\n",
    "    # the instances of this class are songs, identified using either a combination of their\n",
    "    # title and artist names, or an identifier when available\n",
    "    # we track in which file we found the track for (appearance), as well as rating, genre and whether\n",
    "    # it is in the library or not\n",
    "    \n",
    "    def __init__(self, identifier):\n",
    "        self.identifier = identifier\n",
    "        self.titles = []\n",
    "        self.artist = None\n",
    "        self.is_in_lib = False\n",
    "        self.appearances = []\n",
    "        self.genre = []\n",
    "        self.apple_music_id = []\n",
    "        self.rating = []\n",
    "    \n",
    "    def has_title_name(self, title):\n",
    "        if title in self.titles:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def add_title(self, title):\n",
    "        self.titles.append(title)\n",
    "    \n",
    "    def set_artist(self, artist):\n",
    "        self.artist = artist\n",
    "    \n",
    "    def set_apple_music_id(self, apple_music_id):\n",
    "        if apple_music_id not in self.apple_music_id:\n",
    "            self.apple_music_id.append(apple_music_id)\n",
    "               \n",
    "    def set_library_flag(self):\n",
    "        self.is_in_lib = True\n",
    "    \n",
    "    def set_genre(self, genre):\n",
    "        if type(genre) != float:\n",
    "            if genre not in self.genre:\n",
    "                self.genre.append(genre.strip())\n",
    "        \n",
    "    def add_appearance(self, appearance_dict):\n",
    "        self.appearances.append(appearance_dict)\n",
    "        \n",
    "    def set_rating(self, rating):\n",
    "        if rating == 'LOVE' or rating == 'LIKE':\n",
    "            if rating not in self.rating:\n",
    "                self.rating.append(rating)\n",
    "        elif rating == 'DISLIKE':\n",
    "            if rating not in self.rating:\n",
    "                self.rating.append(rating)\n",
    "        \n",
    "        \n",
    "#Helper functions     \n",
    "def concatenate_title_artist(title, artist):\n",
    "    '''\n",
    "        This function returns a concatenated string without any trailing spaces of the title and\n",
    "        artist names passed as arguments to the function. The output of this function: Title && Artist\n",
    "    '''\n",
    "    return title.strip()+' && '+artist.strip() ###strip() function gets rid of the trailing spaces and the + operator concatenates the two strings in the format Title && Artist\n",
    "\n",
    "def instantiate_track(title, artist):\n",
    "    '''\n",
    "        Creates an instance of the Track class, setting both the title and artist\n",
    "        names used when creating it (multiple titles may be found latter on and added \n",
    "        to the list of titles for this track\n",
    "    '''\n",
    "    track_instance = Track(increment)\n",
    "    track_instance.add_title(title)\n",
    "    track_instance.set_artist(artist)\n",
    "    return track_instance\n",
    "            \n",
    "def update_track_from_library(track_instance, index, row):\n",
    "    '''\n",
    "        For a given track instance, updates the properties of the track using the library\n",
    "        tracks dataframe:\n",
    "            - its appearance in the library_tracks_info_df, and at which index\n",
    "            - the genre and rating of the song when available\n",
    "            - the flag is_in_lib\n",
    "            - any of the available identifiers used to identify the track\n",
    "    '''\n",
    "    track_instance.set_library_flag()\n",
    "    track_instance.add_appearance({'source': 'library_tracks', 'df_index':index})\n",
    "    track_instance.set_genre(row['Genre'])\n",
    "    if row['Genre'] not in genres_list:\n",
    "        genres_list.append(row['Genre'])\n",
    "    track_instance.set_rating(row['Track Like Rating'])\n",
    "    if str(row['Apple Music Track Identifier'])!='nan':\n",
    "        track_instance.set_apple_music_id(str(int(row['Apple Music Track Identifier'])))\n",
    "    else:\n",
    "        track_instance.set_apple_music_id(str(int(row['Track Identifier'])))\n",
    "        if str(row['Purchased Track Identifier']) !='nan':\n",
    "            track_instance.set_apple_music_id(str(int(row['Purchased Track Identifier'])))\n",
    "\n",
    "def update_track_from_play_activity(track_instance, index, row):\n",
    "    '''\n",
    "        For a given track instance, updates the properties of the track using the play\n",
    "        activity dataframe:\n",
    "            - its appearance in the play_activity_df, and at which index\n",
    "            - the flag is_in_lib whenever the song was found from the library\n",
    "    '''\n",
    "    track_instance.add_appearance({'source': 'play_activity', 'df_index':index})\n",
    "    if row['Track origin'] == 'library' and track_instance.is_in_lib is False:\n",
    "            track_instance.set_library_flag()\n",
    "            \n",
    "def comparison_titles_for_artist(artist, title_to_compare):\n",
    "    '''\n",
    "        Compares the string similarity of any song associated to an artist and an unknown\n",
    "        title for this artist. The goal here is to be able to match different spellings of \n",
    "        the same song. \n",
    "        If the similarity score is above the threshold set, it returns the track instance\n",
    "        of the matching artist song we already know. \n",
    "        Otherwise it returns 'No match'.\n",
    "    '''\n",
    "    for artist_track in artist_tracks_titles[artist]: ### here you run a loop to scan through the song titles associated with a specific artist\n",
    "        title_similarity_for_artist = similarity (title_to_compare, artist_track)\n",
    "        # value observed to bring consistently a match between similar songs\n",
    "        if title_similarity_for_artist > 0.625:\n",
    "            #we fetch the track instance associated with the close match\n",
    "            title_artist_combination = concatenate_title_artist(artist_track, artist)\n",
    "            track_instance = track_instance_dictionary[title_artist_combination] \n",
    "            return track_instance\n",
    "    return 'No match'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22925d3",
   "metadata": {},
   "source": [
    "#### The logic is as follows:\n",
    "STEP 1: We loop through the Apple Music Library dataframe and we create a track instance whenever we encounter a new song. We update an existing track instance when we have seen this song before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8a75d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we build our tracks instances using the library tracks related information dataframe\n",
    "def process_library_tracks_dataframe(library_tracks_information_df):\n",
    "    '''\n",
    "        This function goes through each row of the library tracks related information dataframe, creating and updating\n",
    "        track instances as they appear. \n",
    "        As this is the first dataframe we go through, we want to create new instances whenever\n",
    "        we are not facing untitled songs (songs with NaN as a title in the dataframe)\n",
    "        The logic works as follows for each row of this dataframe:\n",
    "            - we look only at rows with a title different than NaN, and we set the artist to\n",
    "            'No Artist' if the artist is also NaN\n",
    "            - if the track is not present in the dictionary of track instances, it means that we never\n",
    "            saw the combination of title/artist of this row. So two options here:\n",
    "                - either we know this artist and we can find a similar title in the artist dictionary and in\n",
    "                this case we update the existing track using update_track_from_library or we know the artist but can't \n",
    "                find a similar title in the artist dictionary, in this case we create a new track instance\n",
    "                using instantiate_track and then update the track using update_track_from_library\n",
    "                - or we do not know this artist, in this case we create a new track instance using instantiate_track and then\n",
    "                update_track_from_library\n",
    "            - else, we update the existing track using update_track_from_library when we have seen the title && artist combination before\n",
    "    '''\n",
    "    global increment  # we assign a global scope to the increment variable in order to access, read and write this global variable inside any function\n",
    "    for index, row in library_tracks_information_df.iterrows(): ## we use .iterrows() to iterate over the dataframe which returns an index value and a series for each row\n",
    "        if str(row['Title']) != 'nan': ### comparison of strings \n",
    "            title = row['Title']\n",
    "            if str(row['Artist']) != 'nan':\n",
    "                artist = row['Artist']\n",
    "            else:\n",
    "                artist = 'No Artist'\n",
    "\n",
    "            title_artist_combined = concatenate_title_artist(title, artist) ### Utilizing helper function defined above\n",
    "\n",
    "            if title_artist_combined not in track_instance_dictionary.keys(): ### the keys for this dictionary are title&&artist combinations\n",
    "                if artist in artist_tracks_titles.keys(): ### the keys for this dictionary are various artists\n",
    "                    titles_comparison_result = comparison_titles_for_artist(artist, title)\n",
    "                    \n",
    "                     ### When we don't find a close match of particular title for an artist\n",
    "                    if titles_comparison_result == 'No match':\n",
    "                        #we instantiate the Track object\n",
    "                        track_instance = instantiate_track(title, artist)\n",
    "                        update_track_from_library(track_instance, index, row)\n",
    "                        #we update the dictionary that keeps track of our instances, and increment\n",
    "                        track_instance_dictionary[title_artist_combined] = track_instance\n",
    "                        increment+=1\n",
    "\n",
    "                    else: \n",
    "                        ### When we know the artist and can find a similar title in the artist dictionary\n",
    "                        track_instance = titles_comparison_result\n",
    "                        if not track_instance.has_title_name(title):\n",
    "                            track_instance.add_title(title)\n",
    "                        update_track_from_library(track_instance, index, row)\n",
    "                        #we also track the match in the track_instances and artist dictionary\n",
    "                        track_instance_dictionary[title_artist_combined] = track_instance\n",
    "                        artist_tracks_titles[artist].append(title)\n",
    "                else:\n",
    "                    #When we don't know the artist and the song was never seen, so we instantiate a new Track\n",
    "                    track_instance = instantiate_track(title, artist)\n",
    "                    update_track_from_library(track_instance, index, row)\n",
    "                    #we update the dictionary that keeps track of our instances, and increment\n",
    "                    track_instance_dictionary[title_artist_combined] = track_instance\n",
    "                    increment+=1\n",
    "                    \n",
    "\n",
    "\n",
    "            else: \n",
    "                # when we have seen the same title && artist combination before, we update the existing track\n",
    "                track_instance_dictionary[title_artist_combined] = track_instance\n",
    "                update_track_from_library(track_instance, index, row)\n",
    "\n",
    "\n",
    "            #we update the artist/track names dictionary where the key is the artist name\n",
    "            ## and the values assigned to it are the various song titles\n",
    "            if artist not in artist_tracks_titles:\n",
    "                artist_tracks_titles[artist]=[]\n",
    "            if title not in artist_tracks_titles[artist]:\n",
    "                artist_tracks_titles[artist].append(title)\n",
    "        else:\n",
    "            items_not_matched['library_tracks'].append(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a026eb",
   "metadata": {},
   "source": [
    "STEP 2: We loop through Identifier Information. As this dataframe contains only title and id, we are not going to be able to create new instances of Tracks (too little information about a track), so we simply update existing instances when we find a match with the ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c2e044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_identifier_dataframe(identifier_dataframe):\n",
    "    '''\n",
    "        This function goes through each row of the identifier information dataframe, updating\n",
    "        track instances as they appear.\n",
    "        Unlike for the tracks dataframe, we have very limited information here, just an identifier\n",
    "        and a title (not even an artist name). So we need to have a different approach, only\n",
    "        based on the identifiers. Which may excluse some songs... But prevents false positives.\n",
    "        The logic works as follows, knowing that we do this for each row of the dataframe:\n",
    "            - we loop through all the track instances we created so far, and see if any of their \n",
    "            identifier matches the id of the row we are looking at\n",
    "            - if it matches, and if we didn't already have the associated title, we add it to the\n",
    "            list of titles of that track\n",
    "            - otherwise, we add it to the tracks we could not match and we ignored.\n",
    "    '''\n",
    "    global increment\n",
    "    for index, row in identifier_dataframe.iterrows():\n",
    "        found_match = False\n",
    "        for title_name in track_instance_dictionary.keys():\n",
    "            track_instance = track_instance_dictionary[title_name]\n",
    "            if row['Identifier'] in track_instance.apple_music_id:\n",
    "                track_instance.add_appearance({'source': 'identifier_info', 'df_index':index})\n",
    "                if not track_instance.has_title_name(row['Title']):\n",
    "                    track_instance.add_title(row['Title'])\n",
    "                found_match = True\n",
    "                break\n",
    "        if found_match is False:\n",
    "            items_not_matched['identifier_info'].append((index, row['Identifier']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2536427",
   "metadata": {},
   "source": [
    "STEP 3: We loop through the Apple Music Play Activity dataframe and we create a track instance when we encounter a new song. We update an existing instance when we already saw a similar song before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc799362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_play_activity_dataframe(play_activity_dataframe):\n",
    "    '''\n",
    "        This function goes through each row of the play activity dataframe, creating and updating\n",
    "        track instances as they appear.\n",
    "        As this is the dataframe we are able to get the most information from, we want to create\n",
    "        new instances whenever we are not facing unknown songs (songs with NaN as a title in the dataframe)\n",
    "        The approach is very similar to the one used for the library tracks related information dataframe.\n",
    "        \n",
    "        The logic works as follows for each row of the dataframe:\n",
    "            - if the track is in the dictionary of track instances, we update the existing\n",
    "            track using update_track_from_play_activity\n",
    "            - else, we have two options :\n",
    "                - either we know this artist and we can find a similar title in the artist dict,\n",
    "                and in this case we update the existing track using update_track_from_play_activity\n",
    "                - or we do not know this artist, or we do not find a close match of title for this\n",
    "                artist and in this case we create a new track instance using instantiate_track and\n",
    "                then update_track_from_play_activity\n",
    "    '''\n",
    "    global increment ## we assign a global scope to the increment variable\n",
    "    for index, row in play_activity_dataframe.iterrows(): ## we use .iterrows() to iterate over the dataframe\n",
    "        #we want to look only at rows where the name of the song is available\n",
    "        if str(row['Song Title']) != 'nan':\n",
    "            title = row['Song Title']\n",
    "            if str(row['Artist']) != 'nan':\n",
    "                artist = row['Artist']\n",
    "            else:\n",
    "                artist = 'No Artist'\n",
    "        else:\n",
    "            items_not_matched['play_activity'].append(index)\n",
    "            continue\n",
    "            \n",
    "        ## we check if we already saw this track (using title and artist names)\n",
    "        title_artist_combined = concatenate_title_artist(title, artist) ## Utilizing helper function defined above\n",
    "        if title_artist_combined in track_instance_dictionary.keys():\n",
    "            track_instance = track_instance_dictionary[title_artist_combined]\n",
    "            update_track_from_play_activity(track_instance, index, row)\n",
    "\n",
    "        else:\n",
    "            # if we had no match with title and artist, we look for similarity in the title for the artist\n",
    "            \n",
    "            if artist in artist_tracks_titles.keys():\n",
    "                titles_comparison_result = comparison_titles_for_artist(artist, title)\n",
    "                \n",
    "                ### When we don't find a close match of particular title for an artist\n",
    "                if titles_comparison_result == 'No match':\n",
    "                    #we instantiate the Track object\n",
    "                    track_instance = instantiate_track(title, artist)\n",
    "                    update_track_from_play_activity(track_instance, index, row)\n",
    "                    #we update the dictionary that keeps track of our instances, and increment\n",
    "                    track_instance_dictionary[title_artist_combined] = track_instance\n",
    "                    increment+=1\n",
    "\n",
    "                ### When we know the artist and can find a similar title in the artist dictionary\n",
    "                else:\n",
    "                    track_instance = titles_comparison_result\n",
    "                    if not track_instance.has_title_name(title):\n",
    "                        track_instance.add_title(title)\n",
    "                    track_instance.add_appearance({'source': 'play_activity', 'df_index':index})\n",
    "                    #we also track the match in the track_instances and artist dicts\n",
    "                    track_instance_dictionary[title_artist_combined] = track_instance\n",
    "                    artist_tracks_titles[artist].append(title)\n",
    "\n",
    "            # we know we never saw this track because the artist is unknown      \n",
    "            else:\n",
    "                #we update the artist/track names dictionnary\n",
    "                artist_tracks_titles[artist]=[]\n",
    "                artist_tracks_titles[artist].append(title)\n",
    "\n",
    "                #we instantiate the Track object\n",
    "                track_instance = instantiate_track(title, artist)\n",
    "                update_track_from_play_activity(track_instance, index, row)\n",
    "\n",
    "                #we update the dictionary that keeps track of our instances, and increment\n",
    "                track_instance_dictionary[title_artist_combined] = track_instance\n",
    "                increment+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd7061f",
   "metadata": {},
   "source": [
    "STEP 4: We loop through the Apple Music Likes and Dislikes dataframe, and again as this dataframe contains very little information about each track, we update existing instances when we already saw a similar song (similar here meaning with a similar combination of Title and Artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf2b990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we process the likes_dislikes_df, trying to match the item reference, or the title/artist \n",
    "\n",
    "def process_likes_dislikes_dataframe(likes_dislikes_dataframe):\n",
    "    '''\n",
    "        This function goes through each row of the likes_dislikes dataframe, updating\n",
    "        track instances as they appear.\n",
    "        This dataframe contains a small proportion of all the tracks ever listened to, and/or in\n",
    "        the library. As a result, we only want to update existing tracks, and not create new ones.\n",
    "        The logic works as follows, knowing that we do this for each row of the dataframe:\n",
    "            - we loop through all the track instances we created so far, and see if any of their identifier matches the id of the row we are looking at\n",
    "            - if we find a match, we update the track with the rating, appearance, and if we didn't\n",
    "            already have the associated title, we add it to the list of titles of that track\n",
    "            - else:\n",
    "                - if the track is in the dictionary of track instances, we update the existing\n",
    "            track's rating and appearance\n",
    "                - otherwise, we have two options:\n",
    "                    - either we know the artist and we can find a similar title in the artist dict,\n",
    "                and in this case we update the existing track\n",
    "                    - or we do not know this artist, or we do not find a close match of title for this\n",
    "                artist and in this case we add it to the tracks we could not match and we ignored\n",
    "                '''\n",
    "    global increment \n",
    "    for index, row in likes_dislikes_dataframe.iterrows():\n",
    "        #we want to look only at rows where the name of the song is available\n",
    "        if str(row['Title']) != 'nan':\n",
    "            title = row['Title']\n",
    "            if str(row['Artist']) != 'nan':\n",
    "                artist = row['Artist']\n",
    "            else:\n",
    "                artist = 'No Artist'\n",
    "        else:\n",
    "            items_not_matched['likes_dislikes'].append(index)\n",
    "            continue\n",
    "\n",
    "        title_artist = concatenate_title_artist(title, artist)\n",
    "\n",
    "        # first we check using the Item Reference as an id\n",
    "        found_match = False\n",
    "        for title_name in track_instance_dictionary.keys():\n",
    "            track_instance = track_instance_dictionary[title_name]\n",
    "            if row['Item Reference'] in track_instance.apple_music_id:\n",
    "                track_instance.add_appearance({'source': 'likes_dislikes', 'df_index':index})\n",
    "                track_instance.set_rating(row['Preference'])\n",
    "                if not track_instance.has_title_name(row['Title']):\n",
    "                    track_instance.add_title(row['Title'])\n",
    "                    track_instance_dictionary[title_artist] = track_instance\n",
    "                    if row['Title'] not in artist_tracks_titles[artist]:\n",
    "                        artist_tracks_titles[artist].append(title)\n",
    "                found_match = True\n",
    "                break\n",
    "\n",
    "        if found_match is False:\n",
    "            #we check if we already saw this track (using title and artist names)\n",
    "            if title_artist in track_instance_dictionary.keys():\n",
    "                track_instance = track_instance_dictionary[title_artist]\n",
    "                track_instance.add_appearance({'source': 'likes_dislikes', 'df_index':index})\n",
    "                track_instance.set_rating(row['Preference'])\n",
    "\n",
    "            else:\n",
    "                # if we had no match with title and artist, we look for similarity in the title for the artist\n",
    "                if artist in artist_tracks_titles.keys():\n",
    "                    titles_comparison_result = comparison_titles_for_artist(artist, title)\n",
    "                    if titles_comparison_result == 'No match':\n",
    "                        #we add the item to the items_not_matched\n",
    "                        items_not_matched['likes_dislikes'].append(index)\n",
    "                        continue\n",
    "                    else:\n",
    "                        track_instance = titles_comparison_result\n",
    "                        if not track_instance.has_title_name(title):\n",
    "                            track_instance.add_title(title)\n",
    "                        track_instance.add_appearance({'source': 'likes_dislikes', 'df_index':index})\n",
    "                        track_instance.set_rating(row['Preference'])\n",
    "                        track_instance_dictionary[title_artist] = track_instance\n",
    "                        artist_tracks_titles[artist].append(title)\n",
    "                else:\n",
    "                    #we add the item to the items_not_matched,\n",
    "                    #we choose not to add it to the Track instances as the amount of information is little\n",
    "                    #and our reference really is the play activity!\n",
    "                    items_not_matched['likes_dislikes'].append(index)\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8980e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is used to assign a unique id to each track instance\n",
    "increment = 0\n",
    "\n",
    "## this dictionary is used to keep track of the title/artist combination with the reference of the associated track instance\n",
    "track_instance_dictionary = {} ### the keys for this dictionary indicate the title && artist combinations\n",
    "\n",
    "## this is used to keep track of all the titles of an artist, including different spellings of the same title\n",
    "artist_tracks_titles = {} ### the keys for this dictionary indicate the various artists and the song titles are assigned as values to this dictionary\n",
    "\n",
    "## this is used to keep track of all the unique values of genres\n",
    "genres_list = []\n",
    "\n",
    "## this is used to keep track of the rows that were not matched in all dataframes processed\n",
    "## can be used to spot why a given row was excluded from the track instances\n",
    "items_not_matched = {'library_tracks':[], 'identifier_info':[],\n",
    "                     'play_activity':[], 'likes_dislikes':[]}\n",
    "\n",
    "\n",
    "# we process the library tracks related information dataframe\n",
    "process_library_tracks_dataframe(library_tracks_information_dataframe)\n",
    "\n",
    "# we process the identifier information\n",
    "process_identifier_dataframe(identifier_information_dataframe)\n",
    "\n",
    "# we process the play activity\n",
    "process_play_activity_dataframe(play_activity_new_dataframe)\n",
    "\n",
    "# we process the likes and dislikes\n",
    "process_likes_dislikes_dataframe(likes_dislikes_dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a53401",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_tracks_titles.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fc5725",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_instance_dictionary.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6293cb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_instance_dictionary.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ecc395",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_tracks_titles.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a679bb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_tracks_titles.get(\"Drake\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9235625c",
   "metadata": {},
   "source": [
    "### Section 9: Checking for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b7d9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Here. we look at the number of songs with duplicates or discrepancies as we have collected information from \n",
    "multiple dataframes '''\n",
    "\n",
    "c=0\n",
    "for title_artist in track_instance_dictionary.keys():\n",
    "    instance = track_instance_dictionary[title_artist]\n",
    "    if len(instance.genre) > 1:\n",
    "        c+=1\n",
    "        print(title_artist, instance.genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fff07b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Number of songs with more than one genre: ', c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da27f3d",
   "metadata": {},
   "source": [
    "#### This is actually a great thing as it could allow building up recommendations using more than one genre to match songs!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cea4f10",
   "metadata": {},
   "source": [
    "### Section 10: Enrichment of the play activity dataframe using Tracks Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596c2339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a reference to the track instance object when available\n",
    "# add column with rating\n",
    "# add a column with the list of genres\n",
    "\n",
    "def build_index_track_instance_dict(target_df_label):\n",
    "    '''\n",
    "        Returns a dictionary matching the index of the target dataframe with a reference to its\n",
    "        associated Track instance.\n",
    "        \n",
    "        Argument can be of four types, for the four df we used to build the Track instances:\n",
    "            - play_activity\n",
    "            - library_tracks\n",
    "            - likes_dislikes\n",
    "            - identifier_infos\n",
    "    '''\n",
    "    \n",
    "    match_index_instance={}\n",
    "    for title_artist in track_instance_dictionary.keys():\n",
    "        instance = track_instance_dictionary[title_artist]\n",
    "        for appearance in instance.appearances:\n",
    "            if target_df_label in appearance['source']:\n",
    "                if appearance['df_index'] not in match_index_instance:\n",
    "                    match_index_instance[appearance['df_index']] = []\n",
    "                if instance not in match_index_instance[appearance['df_index']]:\n",
    "                    match_index_instance[appearance['df_index']].append(instance)\n",
    "                    match_index_instance[appearance['df_index']].append(instance.is_in_lib)\n",
    "                    match_index_instance[appearance['df_index']].append(instance.rating)\n",
    "                    match_index_instance[appearance['df_index']].append(instance.genre)\n",
    "                    \n",
    "\n",
    "    return match_index_instance\n",
    "\n",
    "# we build the dictionary matching df_analysis indexes with track instance ref\n",
    "match_index_instance_activity = build_index_track_instance_dict('play_activity')  \n",
    "\n",
    "# we convert this dictionary into a df, that we merge with df_analysis to have a new column \n",
    "# containing the ref to the instance\n",
    "index_instance_df = pd.DataFrame.from_dict(match_index_instance_activity, orient='index', columns=['Track Instance', 'Library Track', 'Rating', 'Genres'])\n",
    "df_visualization = pd.concat([play_activity_new_dataframe,index_instance_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da62990f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7543e2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_col_with_list(x):\n",
    "    '''\n",
    "        This function is used to break down the values of a serie containing lists.\n",
    "        The idea is to return the values as a string ('', the unique value of a list, or a join of\n",
    "        values separated by '&&').\n",
    "    '''\n",
    "    if type(x) != float:\n",
    "        if x == None or len(x) == 0:\n",
    "            return 'Unknown'\n",
    "        elif len(x) == 1:\n",
    "            return x[0]\n",
    "        else:\n",
    "            return ' && '.join(x)\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "    \n",
    "df_visualization['Rating'] = df_visualization['Rating'].apply(clean_col_with_list)\n",
    "df_visualization['Genres'] = df_visualization['Genres'].apply(clean_col_with_list)\n",
    "\n",
    "# Let's also replace nan value from genres_list and Library Track and make sure we do not have extra spaces\n",
    "\n",
    "genres_list_clean = [x if str(x) != 'nan' else '' for x in genres_list]\n",
    "genres_list_clean = [x.strip() for x in genres_list_clean]\n",
    "\n",
    "df_visualization['Library Track'].fillna(False, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada2e92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visualization.loc[1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802a5f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Removing the space between the name of the columns for convenience \n",
    "Later on I query rows usign the column names as an attribute of the dataframe'''\n",
    "\n",
    "df_visualization.columns = [c.replace(' ', '_') for c in df_visualization.columns]\n",
    "df_visualization.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231b1fc9",
   "metadata": {},
   "source": [
    "### Section 11: Data Visualization\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a81db11",
   "metadata": {},
   "source": [
    "### Section 11.1 Listening Trends\n",
    "\n",
    "1. Do we observe any trends on my listening activity from 2021 to 2022?\n",
    "2. Can I plot the distribution of tracks listened to per month for each year?\n",
    "3. Can I plot the distribution of tracks listened to per day of the month for each year?\n",
    "4. Can I plot the distribution of tracks listened to per day of the week for each year? Do I listen to songs more on the weekdays or the weekends?\n",
    "5. Can I plot the distribution of tracks listened to per hour of the day? Do I listen to songs more during the day or the night?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdc875e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### We look at which specific years for which we have my listening activity related data\n",
    "df_visualization['Play_Year'].unique() # calling the unique method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22a1098",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## We plot a pie chart after importing plotly.express module as pex\n",
    "year = df_visualization['Play_Year'].unique() ## labels for our pie chart\n",
    "count = df_visualization['Play_Year'].value_counts() ## values used to associate with each sector on the pie chart\n",
    "\n",
    "figure = pex.pie(names = year, values = count, title = \"Distribution in Percentage across 2021 and 2022\",\n",
    "                 color_discrete_sequence= pex.colors.sequential.RdBu)\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69473717",
   "metadata": {},
   "source": [
    "#### 2022 has been the most active year. My listening activity has doubled in 2022 when compared to 2021.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb59b13c",
   "metadata": {},
   "source": [
    "#### Here, I utilize a bar chart to demonstrate the distribution of tracks listened to per month for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6808c923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of tracks listened to per month for different years\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(name='2021',\n",
    "           x = df_visualization[df_visualization['Play_Year']==2021]['Play_Month'].unique(),\n",
    "           y = df_visualization[df_visualization['Play_Year']==2021]['Play_Month'].value_counts(),\n",
    "           marker_color= 'rgb(31, 158, 137)'\n",
    "    ),\n",
    "    go.Bar(name='2022',\n",
    "           x = df_visualization[df_visualization['Play_Year']==2022]['Play_Month'].unique(),\n",
    "           y = df_visualization[df_visualization['Play_Year']==2022]['Play_Month'].value_counts(),\n",
    "           marker_color='rgb(180, 222, 44)'\n",
    "    )\n",
    "])\n",
    "#update the layout\n",
    "fig.update_layout(\n",
    "    title='Distribution of the number of tracks listened to each month for different years',\n",
    "    xaxis=dict(\n",
    "        #title='Month of the year',\n",
    "        tickangle = -45,\n",
    "        tickmode = 'array',\n",
    "        tickvals = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "        ticktext = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Number of tracks listened to',\n",
    "        titlefont_size=16,\n",
    "        tickfont_size=14,\n",
    "    ),\n",
    "    barmode='group',\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a99f67",
   "metadata": {},
   "source": [
    "#### This year, January and October recorded the highest level of listening activity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdd8d17",
   "metadata": {},
   "source": [
    "#### Here, I utilize a bar chart to demonstrate the distribution of tracks listened to per day of each month for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0c4f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of tracks listened to per day of the month for different years\n",
    "\n",
    "fig = make_subplots(rows=2, cols=1, y_title='Number of tracks listened to',)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(name='2021',\n",
    "           x=df_visualization[df_visualization['Play_Year']==2021]['Play_Date'].unique(),\n",
    "           y=df_visualization[df_visualization['Play_Year']==2021]['Play_Date'].value_counts(),\n",
    "           marker_color='rgb(31, 158, 137)'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Bar(name='2022',\n",
    "           x=df_visualization[df_visualization['Play_Year']==2022]['Play_Date'].unique(),\n",
    "           y=df_visualization[df_visualization['Play_Year']==2022]['Play_Date'].value_counts(),\n",
    "           marker_color='rgb(180, 222, 44)'\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Distribution of the number of tracks listened to each day of the month for different years',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abbdab3",
   "metadata": {},
   "source": [
    "#### When I looked at the distribution per day of the month, I notice that there is a slight increase in my listening activity in the first two weeks of each month for 2022.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f3f15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ratio_songs(serie):\n",
    "    return (serie.value_counts()/serie.count())*100\n",
    "\n",
    "'''This user-defined function builds up the title of the plot based on the desired y-axis(Number of Tracks/Percentage)'''\n",
    "def parse_bar_plot_input(df, time_granularity, is_percentage):\n",
    "    if is_percentage is False:\n",
    "        plotted_value = 'number'\n",
    "    else:\n",
    "        plotted_value = 'percentage'\n",
    "\n",
    "    if time_granularity=='hour':\n",
    "        title = ('Distribution of {0} of tracks listened to per hour of the day for different years (in local time)').format(plotted_value)\n",
    "        target_column = \"Play_Hour_in_Local_Time\"\n",
    "    elif time_granularity=='DOM':\n",
    "        title = ('Distribution of {0} of tracks listened to each day of the month for different years').format(plotted_value)\n",
    "        target_column = \"Play_Date\"\n",
    "    elif time_granularity=='DOW':\n",
    "        title = ('Distribution of {0} of tracks listened to per day of the week for different years').format(plotted_value)\n",
    "        target_column = \"Play_Day_of_the_Week\"\n",
    "    elif time_granularity=='month':\n",
    "        title = ('Distribution of {0} of tracks listened to each month for different years').format(plotted_value)\n",
    "        target_column = 'Play_Month'\n",
    "\n",
    "    else:\n",
    "        print('Please specify a valid time_granularity : \"month\", \"DOM\", \"DOW\", \"hour\"')\n",
    "            \n",
    "    y_title = ('{0} of tracks listened to').format(plotted_value)\n",
    "    \n",
    "    return title, target_column, y_title\n",
    "\n",
    "'''This user-defined function gets the count of the number of tracks based on the target column: Day of the week/\n",
    "Hour/Day of the month'''\n",
    "\n",
    "def render_bar_trace(df, fig, row, is_percentage, year, target_column):\n",
    "    if is_percentage:\n",
    "        y_values = compute_ratio_songs(df[df['Play_Year']==year][target_column])\n",
    "    else:\n",
    "        y_values = df[df['Play_Year']==year][target_column].value_counts()\n",
    "    fig.add_trace(\n",
    "        go.Bar(name=str(year),\n",
    "               x=df[df['Play_Year']==year][target_column].unique(),\n",
    "               y=y_values,\n",
    "               marker_color='rgb(68, 1, 84)'\n",
    "        ),\n",
    "        row=row, col=1\n",
    "    )\n",
    "    \n",
    "'''This function builds up the sub-plots for each year'''\n",
    "\n",
    "def render_time_multiple_plots(df, time_granularity, is_percentage=False):\n",
    "\n",
    "    years_to_plot = sorted(df['Play_Year'].dropna().unique())\n",
    "    title, target_column, y_title = parse_bar_plot_input(df, time_granularity, is_percentage)\n",
    "    row = 1\n",
    "    sub_titles = [str(x) for x in years_to_plot]\n",
    "    height = 0\n",
    "\n",
    "    fig = make_subplots(rows=len(years_to_plot), cols=1, y_title=y_title, subplot_titles=sub_titles)\n",
    "\n",
    "    for year in years_to_plot:\n",
    "        render_bar_trace(df, fig, row, is_percentage, years_to_plot[row-1], target_column)\n",
    "        sub_titles.append(years_to_plot[row-1])\n",
    "        row += 1\n",
    "        height += 200\n",
    "\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        showlegend=False,\n",
    "        height = height,\n",
    "    )\n",
    "    fig.update_xaxes(matches='x')\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be17a276",
   "metadata": {},
   "outputs": [],
   "source": [
    "render_time_multiple_plots(df_visualization, 'hour', is_percentage=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e778f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "render_time_multiple_plots(df_visualization, 'DOW', is_percentage=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96e05f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of tracks listened to per day of the week for different years\n",
    "\n",
    "def compute_ratio_songs(serie):\n",
    "    return (serie.value_counts()/serie.count())*100\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(name='2021',\n",
    "           x=df_visualization[df_visualization['Play_Year']==2021]['Play_Day_of_the_Week'].unique(),\n",
    "           y=compute_ratio_songs(df_visualization[df_visualization['Play_Year']==2021]['Play_Day_of_the_Week']),\n",
    "           marker_color='rgb(31, 158, 137)'\n",
    "    ),\n",
    "    go.Bar(name='2022',\n",
    "           x=df_visualization[df_visualization['Play_Year']==2022]['Play_Day_of_the_Week'].unique(),\n",
    "           y=compute_ratio_songs(df_visualization[df_visualization['Play_Year']==2022]['Play_Day_of_the_Week']),\n",
    "           marker_color='rgb(180, 222, 44)'\n",
    "    )\n",
    "])\n",
    "\n",
    "#update the layout\n",
    "fig.update_layout(\n",
    "    title='Distribution of percentage of tracks listened to per day of the week for different years',\n",
    "    xaxis=dict(\n",
    "        categoryorder='array',\n",
    "        tickangle = -45,\n",
    "        categoryarray = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'],\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Percentage of tracks listened to per year',\n",
    "        titlefont_size=16,\n",
    "        tickfont_size=14,\n",
    "    ),\n",
    "    barmode='group',\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bbe8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of tracks listened to per hour of the day for different years\n",
    "\n",
    "fig = make_subplots(rows=2, cols=1, y_title='Percentage of tracks listened to')\n",
    "\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(name='2021',\n",
    "           x=df_visualization[df_visualization['Play_Year']==2021]['Play_Hour_in_Local_Time'].unique(),\n",
    "           y=compute_ratio_songs(df_visualization[df_visualization['Play_Year']==2021]['Play_Hour_in_Local_Time']),\n",
    "           marker_color='rgb(31, 150, 139)'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(name='2022',\n",
    "           x=df_visualization[df_visualization['Play_Year']==2022]['Play_Hour_in_Local_Time'].unique(),\n",
    "           y=compute_ratio_songs(df_visualization[df_visualization['Play_Year']==2022]['Play_Hour_in_Local_Time']),\n",
    "           marker_color='rgb(184, 222, 41)'\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "fig.update_layout(\n",
    "    title='Distribution of percentage of tracks listened to per hour of the day for different years (in local time)',\n",
    "    height=500\n",
    ")\n",
    "fig.update_xaxes(matches='x')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8f9b08",
   "metadata": {},
   "source": [
    "#### When we look at the distribution per day of the week, activity is higher during the week in comparison to the weekends. Additionally, the plot clearly shows I am actively listening to more songs during the night for both years."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d29329",
   "metadata": {},
   "source": [
    "### Section 11.2:  Listening Duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e281474",
   "metadata": {},
   "source": [
    "#### For this section, I answer the following questions:\n",
    "1. Can I develop a visualization which depicts the number of minutes spent per day listening to music in 2022 and 2021 and compare trends between these two years?\n",
    "2. Can I develop a visualization which depicts my listening patterns/trends for these three genres: Rap, Pop, and Electronic?\n",
    "3. Can I develop a visualization which depicts my listening patterns/trends for my two favourite artists: Eminem and Russ?\n",
    "4. Can I develop a visualization which depicts my listening pattern for the artist(Sickick) whom I discovered later this year?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c99f107",
   "metadata": {},
   "source": [
    "### Here, I try to build a more complex visualization using a heatmap to show the number of minutes played for each day of our dataset. HeatMaps allow the visualization of three features with categorical features along the X and Y Axes and a third continuous feature displayed through color inside the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a372c431",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Plotly offers a high level API(plotly express library) and a low level API(graph objects library) to create \n",
    "visualizations. Here, we use the graph objects library as we have more control on making modifications\n",
    "to our visualizations.'''\n",
    "\n",
    "''' I decided to use 2D Histograms(also called Density Plots) which combines two different histograms and helps to\n",
    " visualize the density of overlaps or concurrences between the two histograms.'''\n",
    "\n",
    "fig = go.Figure(go.Histogram2d(\n",
    "        y = df_visualization[df_visualization['Play_Year'] == 2022]['Play_Date'],\n",
    "        x = df_visualization[df_visualization['Play_Year'] == 2022]['Play_Month'],\n",
    "        autobiny = False, ## the auto-determined bin attributes are set to FALSE\n",
    "        ybins = dict(start=0.5, end=31.5, size=-1), ## we update the bin attributes accordingly \n",
    "        autobinx = False,\n",
    "        xbins = dict(start=0.5, end=12.5, size=1),\n",
    "        z = df_visualization[df_visualization['Play_Year'] == 2022]['Play_duration_in_minutes'],\n",
    "        histfunc = \"sum\" ## we specify the binning function to 'sum' so that the histogram values are computed \n",
    "                        ### using the sum of the minutes of all tracks played each day\n",
    "    ))\n",
    "'''Here, I properly label axis ticks in order to better communicate information through my graphical visualizations.'''\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Heat map of the play duration in minutes for each day in 2022',\n",
    "    xaxis=dict(\n",
    "        tickangle = -45, ## sets the angle of the labels with respect to the horizontal axis\n",
    "        tickmode = 'array', ## we assign the tickmode property to array\n",
    "        tickvals = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], ## we provide a list of values and labels through tickvals and ticktext\n",
    "        ticktext = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7611754",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Developing a similar heatmap for 2021'''\n",
    "fig = go.Figure(go.Histogram2d(\n",
    "        y = df_visualization[df_visualization['Play_Year'] == 2021]['Play_Date'],\n",
    "        x = df_visualization[df_visualization['Play_Year'] == 2021]['Play_Month'],\n",
    "        autobiny = False, ## the auto-determined bin attributes are set to FALSE\n",
    "        ybins = dict(start=0.5, end=31.5, size=-1), ## we update the bin attributes accordingly \n",
    "        autobinx = False,\n",
    "        xbins = dict(start=0.5, end=12.5, size=1),\n",
    "        z = df_visualization[df_visualization['Play_Year'] == 2021]['Play_duration_in_minutes'],\n",
    "        histfunc = \"sum\" ## we specify the binning function to 'sum' so that the histogram values are computed \n",
    "                        ### using the sum of the minutes of all tracks played each day\n",
    "    ))\n",
    "\n",
    "'''Here, I properly label axis ticks in order to better communicate information through my graphical visualizations.'''\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Heat map of the play duration in minutes for each day in 2021',\n",
    "    xaxis=dict(\n",
    "        tickangle = -45, ## sets the angle of the labels with respect to the horizontal axis\n",
    "        tickmode = 'array', ## we assign the tickmode property to array\n",
    "        tickvals = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], ## we provide a list of values and labels through tickvals and ticktext\n",
    "        ticktext = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461ea6a3",
   "metadata": {},
   "source": [
    "#### After managing to plot heat maps of the listening time per day of each month for each year, let's plot it for both 2021 and 2022 so that we can actually compare the trends across years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c055c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''The .make_subplots() function produces a graph object that is pre-configured with a grid of subplots.\n",
    "After constructing the graph object figure, it can be updated by adding traces sequentially\n",
    "by using the add_trace() function. We supply the row and col arguments to add_trace() to add a trace \n",
    "to a particular subplot.'''\n",
    "\n",
    "fig = make_subplots(rows=2, cols=1, y_title='Day of the month',\n",
    "                    subplot_titles=(\"2021\", \"2022\"))\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram2d(\n",
    "        y=df_visualization[df_visualization['Play_Year']==2021]['Play_Date'],\n",
    "        x=df_visualization[df_visualization['Play_Year']==2021]['Play_Month'],\n",
    "        autobiny=False,\n",
    "        ybins=dict(start=0.5, end=31.5, size=1),\n",
    "        autobinx=False,\n",
    "        xbins=dict(start=0.5, end=12.5, size=1),\n",
    "        z=df_visualization[df_visualization['Play_Year']==2021]['Play_duration_in_minutes'],\n",
    "        histfunc=\"sum\",\n",
    "        coloraxis=\"coloraxis\",\n",
    "        hovertemplate=\n",
    "        \"%{y} %{x} 2021\" +\n",
    "        \"Time listening: %{z:,.0f} minutes\" +\n",
    "        \"\",\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram2d(\n",
    "        y=df_visualization[df_visualization['Play_Year']==2022]['Play_Date'],\n",
    "        x=df_visualization[df_visualization['Play_Year']==2022]['Play_Month'],\n",
    "        autobiny=False,\n",
    "        ybins=dict(start=0.5, end=31.5, size=1),\n",
    "        autobinx=False,\n",
    "        xbins=dict(start=0.5, end=12.5, size=1),\n",
    "        z=df_visualization[df_visualization['Play_Year']==2022]['Play_duration_in_minutes'],\n",
    "        histfunc=\"sum\",\n",
    "        coloraxis=\"coloraxis\",\n",
    "        hovertemplate=\n",
    "        \"%{y} %{x} 2022\" +\n",
    "        \"Time listening: %{z:,.0f} minutes\" +\n",
    "        \"\",\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Heat map of the play duration in minutes for each day',\n",
    "    height=900,\n",
    "    coloraxis=dict(colorscale='hot'),\n",
    "    showlegend=False,\n",
    ")\n",
    "fig.update_xaxes(tickangle = -45, \n",
    "                 tickmode = 'array', \n",
    "                 tickvals = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "                 ticktext = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'],\n",
    "                 row=1, col=1)\n",
    "fig.update_xaxes(tickangle = -45, \n",
    "                 tickmode = 'array', \n",
    "                 tickvals = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "                 ticktext = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'],\n",
    "                 row=2, col=1)\n",
    "\n",
    "fig.update_xaxes(matches='x')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdff0205",
   "metadata": {},
   "source": [
    "#### On comparison, the time spent listening to music in 2022 has increased considerably. We observe darker shades of red and orange in 2022 when compared to 2021. In 2022, I spent more time listening to music in the month of October, notably due to the amount of time spent cleaning and manipulating the data for this project. I love working while grooving to unique tracks as it boosts my productivity. Interestingly, I spent 2,200 minutes(equivalent to 37 hours) listening to music on October 14th this year. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a1681e",
   "metadata": {},
   "source": [
    "#### Now, we will play with filters on this visualization. For example, we want to visualize the time spent listening to my favourite genres or favourite artists each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bd4e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_params_default = {\n",
    "    'year': df_visualization['Play_Year'].unique(),\n",
    "    'genre':[],\n",
    "    'artist':[],\n",
    "    'title':[],\n",
    "    'rating':[],\n",
    "    'origin':[],\n",
    "    'offline':[],\n",
    "    'library':[],\n",
    "    'skipped':[],\n",
    "}\n",
    "\n",
    "def manage_query_filters(query_params=query_params_default, filter_on_single_year=''):\n",
    "    '''\n",
    "        This function returns a query that can be used to filter the dataframe.\n",
    "        It takes as an input a query_type, of type str, that can take the following values:\n",
    "            - genre\n",
    "            - artist\n",
    "            - title\n",
    "            - rating\n",
    "            - origin\n",
    "            - offline\n",
    "            - library\n",
    "            - skipped\n",
    "        It takes as a second argument query_values, a list of strings, that should contain\n",
    "        any of the strings that we want to match to the query_type. For example, we can search\n",
    "        for ['Pop', 'Rock', 'Soundtrack'] in query_type == 'genre'. The search uses partial match\n",
    "        with OR OPERATOR (if the column Genres of the df contains any of these strings).\n",
    "        \n",
    "        Finally, it takes as a argument the year we want to filter for (passed as an input\n",
    "        for the query, and not as an argument for the plot)\n",
    "        \n",
    "        Example: This function returns the output in the form:\n",
    "        year 2022 AND (genre 'Pop' OR 'Rap' OR 'Dance')\n",
    "    '''\n",
    "    if filter_on_single_year != '':\n",
    "        query = build_numeric_query_element('Play_Year', filter_on_single_year)\n",
    "    else:\n",
    "        query = build_numeric_query_element('Play_Year', query_params['year'])\n",
    "\n",
    "    query = query + build_data_query(query_params)\n",
    "    \n",
    "    return query\n",
    "\n",
    "def build_query_element(category, query_values):\n",
    "    '''\n",
    "        This function builds the string that is used as a query to filter the dataframe.\n",
    "        Depending on the number of arguments passed in query_values, the format of the query changes.\n",
    "        Mix of AND between the date and the category search, and OR between each value of the\n",
    "        category we want to search for. Here, we use the .format() method which formats the specified values and \n",
    "        inserts them inside the string's placeholder. The placeholder is defined using curly brackets.\n",
    "        The placeholder can be identified using numbered indexes like {0} and {1}.\n",
    "        \n",
    "        \n",
    "        Example: This function returns the output in the form:\n",
    "        (genre 'Pop' OR 'Rap' OR 'Dance')\n",
    "    '''\n",
    "    if len(query_values) == 1:\n",
    "        query_element = '{0}.str.contains(\"{1}\")'.format(category, query_values[0]) ##.str.contains() is used to filter\n",
    "                                                                                ### for rows that contain the substring\n",
    "    elif len(query_values) == 2:\n",
    "        first_item = '{0}.str.contains(\"{1}\")'.format(category, query_values[0])\n",
    "        last_item = '{0}.str.contains(\"{1}\")'.format(category, query_values[-1])\n",
    "        query_element = '(' + first_item + '|' + last_item + ')'\n",
    "    else:\n",
    "        first_item = '{0}.str.contains(\"{1}\")'.format(category, query_values[0])\n",
    "        last_item = '{0}.str.contains(\"{1}\")'.format(category, query_values[-1])\n",
    "        query_element = '(' + first_item + '|'\n",
    "        for k in range(1, len(query_values)-1):\n",
    "            query_element = query_element + '{0}.str.contains(\"{1}\")'.format(category, query_values[k]) + '|'\n",
    "        query_element = query_element + last_item + ')'\n",
    "    \n",
    "    return query_element\n",
    "\n",
    "\n",
    "def build_numeric_query_element(category, query_values):\n",
    "    ''' \n",
    "    Here, we build the query using .format() method which formats the specified values and inserts them inside the\n",
    "    string's placeholder. The placeholder is defined using curly brackets. The placeholder can be identified using\n",
    "    numbered indexes like {0} and {1}. Depending on the number of arguments passed in query_values, the format\n",
    "    of the query changes.\n",
    "    This function returns the output in the form\n",
    "    (Play_Year == 2021| Play_Year == 2022)\n",
    "    '''\n",
    "    if len(query_values) == 1:\n",
    "        query_element = '{0}=={1}'.format(category, query_values[0])\n",
    "    elif len(query_values) == 2:\n",
    "        first_item = '{0}=={1}'.format(category, query_values[0])\n",
    "        last_item = '{0}=={1}'.format(category, query_values[-1])\n",
    "        query_element = '(' + first_item + '|' + last_item + ')'  ## concatenation of the strings\n",
    "    else:\n",
    "        first_item = '{0}=={1}'.format(category, query_values[0])\n",
    "        last_item = '{0}=={1}'.format(category, query_values[-1])\n",
    "        query_element = '(' + first_item + '|'\n",
    "        for k in range(1, len(query_values)-1):\n",
    "            query_element = query_element + '{0}=={1}'.format(category, query_values[k]) + '|'\n",
    "        query_element = query_element + last_item + ')'\n",
    "    \n",
    "    return query_element \n",
    "\n",
    "\n",
    "def build_boolean_query_element(category, query_values):\n",
    "    '''\n",
    "        This function builds the string that is used as a query to filter the dataframe.\n",
    "        As with boolean category the number of values can only be at most 2 (True, False),\n",
    "        the logic is much simpler than for other categories. \n",
    "        \n",
    "        Example:\n",
    "        year 2018 AND library_track False\n",
    "    '''\n",
    "    query_element = ''\n",
    "    if len(query_values) == 1: ## .isin() method is used to filter by selecting rows which have a particular value\n",
    "        ## in a particular column (True or False in this case)\n",
    "        query_element = query_element + '{0}.isin([{1}])'.format(category, query_values[0])\n",
    "    else:\n",
    "        first_item = '{0}.isin([{1}]'.format(category, query_values[0])\n",
    "        last_item = '{0}.isin([{1}])'.format(category, query_values[-1])\n",
    "        query_element = query_element + '(' + first_item + '|' + last_item + ')'\n",
    "    \n",
    "    return query_element\n",
    "\n",
    "def build_data_query(query_params):\n",
    "    '''\n",
    "        This function is in charge of choosing which column to use in the query \n",
    "        depending on the keys of the query_params dict.\n",
    "        It uses build_query_element to actually put together the query string. \n",
    "    '''\n",
    "    query = ''\n",
    "    for query_category in query_params.keys(): ## the keys include genre, artist, title and other categories we want to \n",
    "                                               ## filter on\n",
    "        target_values = query_params[query_category] ## the values are the specific filters, for example: hip/hop as the \n",
    "                                                    ## value associated with the key 'genre'\n",
    "        if query_category != 'year' and target_values != []:\n",
    "            query = query + '&'\n",
    "            if query_category == 'genre':\n",
    "                query = query + build_query_element('Genres', target_values)\n",
    "            elif query_category == 'artist':\n",
    "                query = query + build_query_element('Artist', target_values)\n",
    "            elif query_category == 'title':\n",
    "                query = query + build_query_element('Title', target_values)\n",
    "            elif query_category == 'rating':\n",
    "                query = query + build_query_element('Rating', target_values)\n",
    "            elif query_category == 'origin':\n",
    "                query = query + build_query_element('Track_origin', target_values)\n",
    "            elif query_category == 'offline':\n",
    "                # as here we compare with booleans, we do not use build_query_element\n",
    "                query = query + build_boolean_query_element('Offline', target_values)\n",
    "            elif query_category == 'library':\n",
    "                query = query + build_boolean_query_element('Library_Track', target_values)\n",
    "            elif query_category == 'skipped':\n",
    "                query = query + build_boolean_query_element('Play_Status', target_values)\n",
    "    return query\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d83d84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_heatmap(df, query_params = query_params_default):\n",
    "    '''\n",
    "        This function is in charge of building and rendering the heatmaps \n",
    "        corresponding to a particular set of conditions (filters on genre,\n",
    "        artist etc.)\n",
    "        It relies on the render_trace function to build each trace of the subplots.\n",
    "    '''\n",
    "    years_to_plot = sorted(query_params['year'])\n",
    "    rows = len(years_to_plot)\n",
    "    row = 1\n",
    "    sub_titles = [str(x) for x in years_to_plot]\n",
    "    height = 0\n",
    "    fig = make_subplots(rows=rows, cols=1, y_title='Day of the month',\n",
    "                       subplot_titles=sub_titles)\n",
    "    \n",
    "    for year in years_to_plot:\n",
    "        query = manage_query_filters(query_params, [year])\n",
    "        filtered_df = df.query(query)\n",
    "        render_trace(fig, row, filtered_df, years_to_plot[row-1])\n",
    "        sub_titles.append(years_to_plot[row-1])\n",
    "        row += 1\n",
    "        height += 500\n",
    "        \n",
    "    fig.update_layout(\n",
    "        title='Heat map of the Play Duration in Minutes for each day',\n",
    "        height = height,\n",
    "        coloraxis=dict(colorscale='viridis'),\n",
    "        showlegend=False,\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(matches='x')\n",
    "    fig.show()\n",
    "    \n",
    "def render_trace(fig, row, df, year):\n",
    " fig.add_trace(\n",
    "        go.Histogram2d(\n",
    "            y=df['Play_Date'],\n",
    "            x=df['Play_Month'],\n",
    "            autobiny=False,\n",
    "            ybins=dict(start=0.5, end=31.5, size=1),\n",
    "            autobinx=False,\n",
    "            xbins=dict(start=0.5, end=12.5, size=1),\n",
    "            z=df['Play_duration_in_minutes'],\n",
    "            histfunc=\"sum\",\n",
    "            coloraxis=\"coloraxis\",\n",
    "            hovertemplate=\n",
    "            \"%{y} %{x} \"+str(year)+\" \" +\n",
    "            \"Time listening: %{z:,.0f} minutes\" +\n",
    "            \"\",\n",
    "        ),\n",
    "        row=row, col=1\n",
    "    )\n",
    " fig.update_xaxes(tickangle = -45, tickmode = 'array', tickvals = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "                 ticktext = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'],\n",
    "                 row=row, col=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6a7898",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Developing a visualization of the time spent listening to Rap Music(my favourite genre)'''\n",
    "query_params = {\n",
    "    'year':df_visualization['Play_Year'].unique(),\n",
    "    'genre':['Rap'],\n",
    "    'artist':[],\n",
    "    'title':[],\n",
    "    'rating':[],\n",
    "    'origin':[],\n",
    "    'offline':[],\n",
    "    'library':[],\n",
    "    'skipped':[],\n",
    "}\n",
    "\n",
    "\n",
    "render_heatmap(df_visualization, query_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d253ecf9",
   "metadata": {},
   "source": [
    "#### Looks like I have been listening to rap music more than ever. 2022 is covered with shades of green with most time spent listening to Rap music in the months of June, July, and October. Interestingly, June and July was the period where I had an outgoing personality. So, it's apparent that I enjoy listening to rap when I am hanging out with my friends. On the other hand, I started with data manipulation for this personal project during the month of October during which I developed overwhelming feelings of anxiety. Listening to these artists regularly helped me overcome my fears and have faith in my dreams. Listening to the stories shared by the artists through music pushed me to work even harder. Hence, I attribute my productivity and philosophy to rap music. Listening to hip hop shields out the noise of the outside world and encourages me to live a life true to myself. In fact, perhaps more than any other genre of music, hip hop embodies the American Dream itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe3b18a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Developing a visualization of the time spent listening to Pop Music(my second favourite genre)'''\n",
    "query_params = {\n",
    "    'year':df_visualization['Play_Year'].unique(),\n",
    "    'genre':['Pop'],\n",
    "    'artist':[],\n",
    "    'title':[],\n",
    "    'rating':[],\n",
    "    'origin':[],\n",
    "    'offline':[],\n",
    "    'library':[],\n",
    "    'skipped':[],\n",
    "}\n",
    "\n",
    "\n",
    "render_heatmap(df_visualization, query_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b0c064",
   "metadata": {},
   "source": [
    "#### As expected, I spent more time listening to pop music during the months of October, November and December in 2021. This was a period of deep sadness for me as I didn't know how to cope up with the present circumstances. The end of a treasured relationship is always difficult, but pop music helped me provide a kind of reverse empathy for the other person in comparison to what I was experiencing. This helped me recognize my own feelings and also distracted me from my own predicament. It greatly helped me in suggesting directions to improve my current situation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ba4624",
   "metadata": {},
   "source": [
    "#### I expect a similar listening pattern for R&B/Soul which envokes a mix of emotions inside me as this genre offers a mix of soul, hip hop, funk, and pop. These artists often relay their own difficult narratives and show that there is a light at the end of the tunnel. The lyrics were capable of uplifting my spirits and improving my mood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d62458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_params = {\n",
    "    'year':df_visualization['Play_Year'].unique(),\n",
    "    'genre':['R&B/Soul'],\n",
    "    'artist':[],\n",
    "    'title':[],\n",
    "    'rating':[],\n",
    "    'origin':[],\n",
    "    'offline':[],\n",
    "    'library':[],\n",
    "    'skipped':[],\n",
    "}\n",
    "\n",
    "\n",
    "render_heatmap(df_visualization, query_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beac55b9",
   "metadata": {},
   "source": [
    "#### Next, I wanted to visualize my listening patterns for Electronic Music as its melodic aspect in combination with the trap foundation makes me feel thought provoking in a different way. The combination of emotion and instrumentation makes it a great genre. They help me feel relaxed one day and energized the next day. Looking at the heat map below confirms the fact that I have started listening to electronic music more often than ever. Again, the maximum time spent per day listening to this genre was observed in October.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff93d29",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "query_params = {\n",
    "    'year':df_visualization['Play_Year'].unique(),\n",
    "    'genre':['Electronic'],\n",
    "    'artist':[],\n",
    "    'title':[],\n",
    "    'rating':[],\n",
    "    'origin':[],\n",
    "    'offline':[],\n",
    "    'library':[],\n",
    "    'skipped':[],\n",
    "}\n",
    "\n",
    "\n",
    "render_heatmap(df_visualization, query_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d459e41",
   "metadata": {},
   "source": [
    "#### Subsequently, I was curious to know how much time did I spend this year listening to my favourite artist, Eminem. Eminem is my favourite artist for a variety of reasons. Throughout his songs, he has spoken about his struggles, discussed controversial topics and told stories – which are brought to life by imagery and metaphors. I admire Eminem for fighting his demons, and for coming back stronger than ever, despite all the hardships he has faced along the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1892be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query_params = {\n",
    "    'year': [2022],\n",
    "    'genre':[],\n",
    "    'artist':['Eminem'],\n",
    "    'title':[],\n",
    "    'rating':[],\n",
    "    'origin':[],\n",
    "    'offline':[],\n",
    "    'library':[],\n",
    "    'skipped':[],\n",
    "}\n",
    "\n",
    "\n",
    "render_heatmap(df_visualization, query_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b298d3a",
   "metadata": {},
   "source": [
    "#### Interestingly, the heatmap looks pretty uniform as opposed to my expectations. There is a spike in listening activity for the month of October though. Next, I investigated my listening activity for another artist: Russ. He knows the power of believing in yourself which has greatly inspired me to achieve my dreams. Lyrics such as \"You decide whether to be your greatest obstacle or your biggest fan\" and \"Don’t hesitate. Don’t doubt. Don’t even worry about falling. Wings will grow.” resonate with me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c7d906",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "query_params = {\n",
    "    'year': [2022],\n",
    "    'genre':[],\n",
    "    'artist':['Russ'],\n",
    "    'title':[],\n",
    "    'rating':[],\n",
    "    'origin':[],\n",
    "    'offline':[],\n",
    "    'library':[],\n",
    "    'skipped':[],\n",
    "}\n",
    "\n",
    "\n",
    "render_heatmap(df_visualization, query_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68125f44",
   "metadata": {},
   "source": [
    "#### Next, I wanted to explore my listening patterns for another artist: Sickick. In a world dominated by the desire for fame, Sickick is the enigmatic artist making a name for himself in music without ever showing his face. Despite his musical talent, the idea of fame and crowds was once a cause of anxiety for Sickick. The iconic mask which is now ubiquitous with his image and music has allowed him to overcome his fears. His music is a complex blend of pop, hip-hop, and EDM. Looking at the heatmap, I listened to his music a lot in the month of June, when I discovered all the tracks that he had produced. But, then I moved to other artists who produced EDM and hence, the time spent listening to his tracks gradually decreased. I respect this artist for introducing me to EDM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8f4cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_params = {\n",
    "    'year': [2022],\n",
    "    'genre':[],\n",
    "    'artist':['Sickick'],\n",
    "    'title':[],\n",
    "    'rating':[],\n",
    "    'origin':[],\n",
    "    'offline':[],\n",
    "    'library':[],\n",
    "    'skipped':[],\n",
    "}\n",
    "\n",
    "\n",
    "render_heatmap(df_visualization, query_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55acfef",
   "metadata": {},
   "source": [
    "#### This observation was pretty intriguing for me. I discovered this artist in the month of January through one of my friends who's a big fan of Russ. The heatmap clearly shows that the maximum time spent listening to his songs was in the month of January, a period when I still lacked self-belief and hence, could not relate to his songs as much as I do now. Infact, the prominent shades of blue in the month of February depict that I didn't even listen to the artist after that day in January until March, a period during which I started believing in myself again. It's very surprising that my music taste reflects the personality changes I was going through."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da9edb1",
   "metadata": {},
   "source": [
    "### Section 11.3: Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64d47f6",
   "metadata": {},
   "source": [
    "For this section, I answer the following questions:\n",
    "1. Can I establish a ranking of artists and the genres of music I like to listen to for each year: 2021 and 2022?  \n",
    "2. Can I establish a ranking of my favourite song titles for each year?\n",
    "3. Can I establish a similar ranking for each month of the present year?\n",
    "4. Do we observe any difference between rankings for each month?\n",
    "5. Can I establish a ranking of genres for each month which observed an increase in listening activity in comparison to the previous month's listening activity for the present year?\n",
    "6. Can I establish a ranking of artists for each month which observed an increase in listening activity in comparison to the previous month's listening activity for the present year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfe4a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' These user-defined function take ranking_target as one of the arguments. We use four kinds of ranking targets: \n",
    "Genres, Artist, Song Title, and Track Origin. These ranking targets represent the categories based on which we develop\n",
    "a ranking, for example, if we pass artist as a ranking target, we will develop a ranking for the artists in the \n",
    "dataframe. The second parameter, query_params, is used to further filter the rankings. For example, if we pass an \n",
    "argument to filter the artists based on a particular genre: Rap, we would develop a ranking of my top Hip-Hop\n",
    "artists. '''\n",
    "\n",
    "\n",
    "'''Here I create an user-defined function which helps to get the count of songs per genre in our dataframe'''\n",
    "\n",
    "def create_genres_count_dictionary(dataframe_genres, genres_list):\n",
    "    genres_count_dictionary = {} ### we initialize as an empty dictionary\n",
    "    ## the keys for this dictionary are the unique genres\n",
    "    ## the values assigned to the keys indicate the number of times each genre has appeared\n",
    "    for reference_genre in genres_list:\n",
    "        genres_count_dictionary[reference_genre] = 0 ## we assign the number of times each genre has occured to zero\n",
    "    for dataframe_genre in dataframe_genres.tolist(): ## .tolist() converts the column's datatype to a list\n",
    "        if '&&' in dataframe_genre: ## for songs that have two or more genres associated with it\n",
    "            genres = dataframe_genre.split('&&') ## would return a list of genres after the split for each song\n",
    "            for genre in genres: \n",
    "                if genre.strip() in genres_count_dictionary.keys(): ##.strip() removes any trailing spaces for each genre\n",
    "                    genres_count_dictionary[genre.strip()] += 1 ## increments the count value by 1 for each genre\n",
    "        else:\n",
    "            if dataframe_genre in genres_count_dictionary.keys(): ## for songs that have a single genre associated with it\n",
    "                genres_count_dictionary[dataframe_genre] += 1 ## increments the count value by 1 for each genre\n",
    "    return genres_count_dictionary ## the resultant dictionary with all unique genres as the keys and the values \n",
    "                                  ## assigned to the keys are the number of times each unique genre has appeared\n",
    "    \n",
    "'''Here, I create an user-defined function which helps me to get the count of songs per Artist/Song_Title/TrackOrigin'''\n",
    "\n",
    "def build_count_dict(df_target):\n",
    "    ref_list = df_target.unique()\n",
    "    \n",
    "    count_dict = {} ### we initialize as an empty dictionary\n",
    "    for ref_elem in ref_list:\n",
    "        if str(ref_elem) != 'nan':\n",
    "            count_dict[ref_elem] = 0\n",
    "    for df_elem in df_target.tolist():\n",
    "        if str(df_elem) != 'nan':\n",
    "            if df_elem in count_dict.keys():\n",
    "                count_dict[df_elem] += 1 ## increments the count value by 1 \n",
    "        else:\n",
    "            continue      \n",
    "    return count_dict\n",
    "\n",
    "'''This user-defined function first filters the dataframe based on the query provided(filters for additional rankings)\n",
    "and then gets the count of songs based on the ranking target'''\n",
    "\n",
    "def build_ranking_dictionary_year(dataframe, ranking_target, query_params = query_params_default):\n",
    "    ranking_dictionary = {}\n",
    "    for year in query_params['year']:\n",
    "        query = manage_query_filters(query_params, [year])\n",
    "        filtered_df = df_visualization.query(query)\n",
    "        if ranking_target == 'Genres':\n",
    "            ranking_dictionary[year] = create_genres_count_dictionary(filtered_df[ranking_target], genres_list_clean)\n",
    "        elif ranking_target in ['Artist', 'Track_origin', 'Song_Title']:\n",
    "            ranking_dictionary[year] = build_count_dict(filtered_df[ranking_target])   \n",
    "    return ranking_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1ceab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Here, I create an user-defined function which build sunburst plots and helps me to visualize hierarchial data'''\n",
    "\n",
    "def build_sunburst_arrays(ranking_dict, ranking_target):\n",
    "    labels = []\n",
    "    parents = []\n",
    "    values = []\n",
    "    ids = []\n",
    "    for year in ranking_dict.keys():\n",
    "        current_index = len(labels)\n",
    "        ids.append(str(year))\n",
    "        labels.append(str(year))\n",
    "        parents.append(ranking_target)\n",
    "        total_count = 0\n",
    "        for genre in ranking_dict[year].keys():\n",
    "            ids.append(str(year)+' - '+genre)\n",
    "            labels.append(genre)\n",
    "            parents.append(str(year))\n",
    "            values.append(ranking_dict[year][genre])\n",
    "            total_count += ranking_dict[year][genre]\n",
    "        values.insert(current_index, total_count)\n",
    "    return labels, parents, values, ids\n",
    "\n",
    "\n",
    "def render_sunburst_plot(df, ranking_target, query_params=query_params_default):\n",
    "    ranking_dict = build_ranking_dictionary_year(df, ranking_target, query_params)\n",
    "    labels, parents, values, ids = build_sunburst_arrays(ranking_dict, ranking_target)\n",
    "    fig =go.Figure(go.Sunburst(\n",
    "        ids=ids,\n",
    "        labels=labels,\n",
    "        parents=parents,\n",
    "        values=values,\n",
    "        branchvalues=\"total\",\n",
    "        insidetextorientation='radial'\n",
    "    ))\n",
    "    # Update layout for tight margin\n",
    "    fig.update_layout(\n",
    "        title = 'Ranking across years of ' + ranking_target,\n",
    "        margin = dict(l=0, r=0, b=0)\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf6433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This function builds a dataframe from the dictionary using the .items() function (a list of tuples of key,value\n",
    "pair)'''\n",
    "\n",
    "def builf_df_from_ranking_dict(ranking_dict, ranking_category):\n",
    "    L = sorted([(k,k1,v1) for k,v in ranking_dict.items() for k1,v1 in v.items()], key=lambda x: (x[0], x[1]))\n",
    "    ranking_df = pd.DataFrame(L, columns=['Year', ranking_category, 'Count'])\n",
    "    return ranking_df\n",
    "\n",
    "'''Ranking the top genres for each Year'''\n",
    "query_params = {\n",
    "    'year': df_visualization['Play_Year'].unique(),\n",
    "    'genre':[],\n",
    "    'artist':[],\n",
    "    'title':[],\n",
    "    'rating':[],\n",
    "    'origin':[],\n",
    "    'offline':[],\n",
    "    'library':[],\n",
    "    'skipped':[],\n",
    "}\n",
    "\n",
    "ranking_dict = build_ranking_dictionary_year(df_visualization, 'Genres', query_params)\n",
    "ranking_df = builf_df_from_ranking_dict(ranking_dict, 'Genres')\n",
    "ranking_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292884db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ranking_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9127e4a5",
   "metadata": {},
   "source": [
    "#### Here, we look at the dataframe which displays all the genres that I listened to in 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771c798f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "genres_2021 = ranking_df[ranking_df[\"Year\"] == 2021]\n",
    "genres_2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76134dd",
   "metadata": {},
   "source": [
    "#### A bar chart presents categorical data with rectangular bars with heights that are proportional to the values that they represent. Using bar charts, we can visualize categorical data where the X-Axis represents the categories and the Y-Axis represents the number of occurences for each category.  For our graph, the X-Axis represents all the genres of music(categorical variable) I listened to in 2021 and the Y-Axis represents the number of songs per genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc27451",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_2021 = [go.Bar(x = genres_2021[\"Genres\"], y = genres_2021[\"Count\"])]\n",
    "layout = go.Layout(title = \" Genres for 2021\")\n",
    "figure = go.Figure(data = data_2021, layout = layout)\n",
    "figure.update_layout(xaxis = {'categoryorder':'total descending'}) ### displays in descending order\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99ad92b",
   "metadata": {},
   "source": [
    "### My Top Five Genres for 2021: \n",
    "1. Hip - Hop/ Rap\n",
    "2. Pop\n",
    "3. Alternative\n",
    "4. R&B Soul\n",
    "5. Dance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf4ab4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_2021 = [go.Bar(x = genres_2021[\"Genres\"], y = genres_2021[\"Count\"])]\n",
    "layout = go.Layout(title = \"Top Genres for 2021\")\n",
    "figure = go.Figure(data = data_2021, layout = layout)\n",
    "figure.update_layout(xaxis = {'categoryorder':'total descending'}) ### displays in descending order\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a838cbd2",
   "metadata": {},
   "source": [
    "Here, we look at the dataframe which displays all the genres that I listened to in 2022. For our graph, the X-Axis represents all the genres of music(categorical variable) I listened to in 2022 and the Y-Axis represents the number of songs per genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc468de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "genres_2022 = ranking_df[ranking_df[\"Year\"] == 2022]\n",
    "genres_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f137acdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_2022 = [go.Bar(x = genres_2022[\"Genres\"], y = genres_2022[\"Count\"])]\n",
    "layout = go.Layout(title = \"Genres for 2022\")\n",
    "figure_2 = go.Figure(data = data_2022, layout = layout)\n",
    "figure_2.update_layout(xaxis = {'categoryorder':'total descending'}) ## displays in descending order\n",
    "figure_2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe7afd2",
   "metadata": {},
   "source": [
    "### My Top Five Genres for 2022:\n",
    "\n",
    "1. Hip - Hop/ Rap\n",
    "2. Pop\n",
    "3. Dance\n",
    "4. Alternative\n",
    "5. Electronic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7423bf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2022 = [go.Bar(x = genres_2022[\"Genres\"], y = genres_2022[\"Count\"])]\n",
    "layout = go.Layout(title = \"Top Genres for 2022\")\n",
    "figure_2 = go.Figure(data = data_2022, layout = layout)\n",
    "figure_2.update_layout(xaxis = {'categoryorder':'total descending'}) ## displays in descending order\n",
    "figure_2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e253b3",
   "metadata": {},
   "source": [
    "#### On comparison, it is a runaway WIN for Hip-Hop music for two consecutive years . In 2022, I have listened to rap music thrice as many times as pop music. Pop music retained its second position. Electronic music climbed one spot in the rankings for 2022. It rose to No. 5, up one spot from its No. 6 ranking last year. However, R&B Soul dropped two spots this year, with a No. 6 ranking right behind Electronic music."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f49ab76",
   "metadata": {},
   "source": [
    "#### Next, I wanted to play with some additional filters on these rankings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eaa718",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Ranking my top genres based on the criteria that I have browsed for the song'''\n",
    "\n",
    "query_params = {\n",
    "    'year':df_visualization['Play_Year'].unique(),\n",
    "    'origin':['search']\n",
    "}\n",
    "\n",
    "render_sunburst_plot(df_visualization, 'Genres', query_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ebb9b8",
   "metadata": {},
   "source": [
    "#### I have browsed for more Pop songs in 2021 when compared to 2022. There's a stark difference between the size of the pie in 2021 and 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22a9d7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Ranking my top genres based on the criteria that they have appeared on my radio'''\n",
    "\n",
    "query_params = {\n",
    "    'year':df_visualization['Play_Year'].unique(),\n",
    "    'origin':['radio']\n",
    "}\n",
    "\n",
    "render_sunburst_plot(df_visualization, 'Genres', query_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1390958",
   "metadata": {},
   "source": [
    "#### Hip-hop music has consistently appeared on my stations indicating that the app likes to recommend the kind of music I enjoy listening to\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b829164a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Ranking my top genres based on the criteria that I have skipped the song'''\n",
    "\n",
    "query_params = {\n",
    "    'year':df_visualization['Play_Year'].unique(),\n",
    "    'skipped': [True]\n",
    "}\n",
    "\n",
    "render_sunburst_plot(df_visualization, 'Genres', query_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f785523e",
   "metadata": {},
   "source": [
    "#### This sunburst plot confirms that my odd behaviour of skipping tracks is even reflected when I am listening to rap music."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5d5f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This function builds up the ranking for my top Artists/Song Titles given the number of rankings desired as an input\n",
    "to this function. '''\n",
    "def list_top_ranked(df, ranking_target, num_ranks, query_params=query_params_default):\n",
    "    ranking_dict = build_ranking_dictionary_year(df, ranking_target, query_params)\n",
    "    for year in query_params['year']:\n",
    "        ranking = {key: ranking_dict[year][key] for key in sorted(ranking_dict[year], key=ranking_dict[year].get, reverse=True)[:num_ranks]}\n",
    "        print('Top ranking for '+ str(year))\n",
    "        print('   ', ranking)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fa1ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### My Top Artists for 2021 and 2022\n",
    "\n",
    "query_params = {\n",
    "    'year': df_visualization['Play_Year'].unique()\n",
    "}\n",
    "\n",
    "\n",
    "list_top_ranked(df_visualization, 'Artist', 5, query_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0fa0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### My Top Rap Artists for 2021 and 2022\n",
    "\n",
    "query_params = {\n",
    "    'year': df_visualization['Play_Year'].unique(),\n",
    "    'genre':[\"Hip-Hop/Rap\"]\n",
    "}\n",
    "\n",
    "\n",
    "list_top_ranked(df_visualization, 'Artist', 5, query_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7ae571",
   "metadata": {},
   "outputs": [],
   "source": [
    "### My Top Pop Artists for 2021 and 2022\n",
    "\n",
    "query_params = {\n",
    "    'year': df_visualization['Play_Year'].unique(),\n",
    "    'genre':[\"Pop\"]\n",
    "}\n",
    "\n",
    "\n",
    "list_top_ranked(df_visualization, 'Artist', 5, query_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b52f5a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### My Top Artists for 2021 and 2022 who produce electronic music\n",
    "\n",
    "query_params = {\n",
    "    'year': df_visualization['Play_Year'].unique(),\n",
    "    'genre':[\"Electronic\"]\n",
    "}\n",
    "\n",
    "\n",
    "list_top_ranked(df_visualization, 'Artist', 5, query_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6314b3f5",
   "metadata": {},
   "source": [
    "#### Next, I filter the artist rankings based on whether it’s a library track or not. These rankings display the artists that I listen to the most through my playlists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1a10a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### My Top Rap Artists that I listen through playlists\n",
    "\n",
    "query_params = {\n",
    "    'year': df_visualization['Play_Year'].unique(),\n",
    "    'genre':[\"Rap\"],\n",
    "    'library': [True]\n",
    "}\n",
    "\n",
    "\n",
    "list_top_ranked(df_visualization, 'Artist', 5, query_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be8bf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### My Top Pop Artists that I listen through playlists\n",
    "\n",
    "query_params = {\n",
    "    'year': df_visualization['Play_Year'].unique(),\n",
    "    'genre':[\"Pop\"],\n",
    "    'library': [True]\n",
    "}\n",
    "\n",
    "\n",
    "list_top_ranked(df_visualization, 'Artist', 5, query_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae573309",
   "metadata": {},
   "source": [
    "#### My top Rap and Pop artists in my library closely resemble the top artists derived for the entire year, which reconfirms that I spend most of my time in my library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aa17dd",
   "metadata": {},
   "source": [
    "#### Next, I filter the artist rankings based on the origin of the song and the genre of the song. For example, I wanted to know which are the top 5 rap artists that I manually browse for or consistently appear on my radio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20042577",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### My Top 5 Rap Artists that I listen through browsing\n",
    "\n",
    "query_params = {\n",
    "    'year': df_visualization['Play_Year'].unique(),\n",
    "    'genre':[\"Rap\"],\n",
    "    'origin': ['search']\n",
    "}\n",
    "\n",
    "\n",
    "list_top_ranked(df_visualization, 'Artist', 5, query_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e458418",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### My Top 5 Rap Artists that I listen through radio \n",
    "\n",
    "query_params = {\n",
    "    'year': df_visualization['Play_Year'].unique(),\n",
    "    'genre':[\"Rap\"],\n",
    "    'origin': ['radio']\n",
    "}\n",
    "\n",
    "\n",
    "list_top_ranked(df_visualization, 'Artist', 5, query_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7318552",
   "metadata": {},
   "outputs": [],
   "source": [
    "### My Top 5 Artists who produce electronic music that I listen through radio \n",
    "\n",
    "query_params = {\n",
    "    'year': df_visualization['Play_Year'].unique(),\n",
    "    'genre':[\"Electronic\"],\n",
    "    'origin': ['radio']\n",
    "}\n",
    "\n",
    "\n",
    "list_top_ranked(df_visualization, 'Artist', 5, query_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5a0a08",
   "metadata": {},
   "source": [
    "#### Next, I establish a ranking of my favourite song titles for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e483f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### My Top Tracks for 2021 and 2022\n",
    "\n",
    "query_params = {\n",
    "    'year': df_visualization['Play_Year'].unique()\n",
    "}\n",
    "\n",
    "list_top_ranked(df_visualization,\"Song_Title\", 5, query_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de690120",
   "metadata": {},
   "source": [
    "#### I filter these rankings on the genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5810bf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### My top 5 Rap Tracks for 2021 and 2022\n",
    "\n",
    "query_params = {\n",
    "    'year': df_visualization['Play_Year'].unique(),\n",
    "    'genre': ['Rap']\n",
    "}\n",
    "\n",
    "list_top_ranked(df_visualization,\"Song_Title\", 5, query_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b8323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### My top 5 Pop Tracks for 2021 and 2022\n",
    "\n",
    "query_params = {\n",
    "    'year': df_visualization['Play_Year'].unique(),\n",
    "    'genre': ['Pop']\n",
    "}\n",
    "\n",
    "list_top_ranked(df_visualization,\"Song_Title\", 5, query_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a052449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### My top 5 Tracks that I have searched for in 2021 and 2022\n",
    "\n",
    "query_params = {\n",
    "    'year': df_visualization['Play_Year'].unique(),\n",
    "    'origin': ['search']\n",
    "}\n",
    "\n",
    "list_top_ranked(df_visualization,\"Song_Title\", 5, query_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f39449",
   "metadata": {},
   "source": [
    "### Section 11.4: Listening Habits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8918b9ae",
   "metadata": {},
   "source": [
    "#### Now, moving on to the last part of our analysis, I answer the following questions:\n",
    "1. Can I develop a compact view of how the tracks are usually found?\n",
    "2. Do I skip tracks a lot? Can I observe any trend between 2021 and 2022?\n",
    "3. Can I know how do I usually find songs that are added to my library? Are the suggested songs really relevant?\n",
    "4. Next, can I know my favourite artists that I have discovered through radio?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fd0c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We look at the unique origins for all soundtracks that I have listened to\n",
    "labels = df_visualization['Track_origin'].unique()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888a2a7c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''I decided to use a pie-chart as it shows the size of items proportional to the sum of the items and is really\n",
    "convenient due to the various color codings that it offers for the user to understand the visualizations'''\n",
    "\n",
    "#plotting the track origin for all years using a pie-chart after importing plotly.express module as pex\n",
    "\n",
    "labels = ['library', 'radio', 'other', 'search']  ##labels for our pie chart\n",
    "values = df_visualization['Track_origin'].value_counts() ## values used to associate with each sector on the pie chart\n",
    "\n",
    "figure = pex.pie(names = labels, values = values , title = \"Distribution in percentage of how the tracks were found for 2021 and 2022\",\n",
    "                 color_discrete_sequence= pex.colors.sequential.RdBu)\n",
    "\n",
    "figure.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6844d0e2",
   "metadata": {},
   "source": [
    "#### 67 percent of the tracks that I have listened to originate from my library which was quite expected as I love making new playlists every month and I mostly listen to it until I get bored. Surprisingly, I listen to the personalized radio on Apple Music more often than expected in order to find more songs that are unique to me. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e9bd13",
   "metadata": {},
   "source": [
    "#### Now, I decided to look at the ratio of songs skipped versus listened to completely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347b396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This function builds up the percentage of completed tracks and partially listened tracks in comparison to all\n",
    "tracks listened to during that particular year \n",
    "'''\n",
    "def build_partial_listening_plot(df):\n",
    "    years = df['Play_Year'].unique() \n",
    "    df_track_complete = df[df['Play_Status'] == True] ## gives a list of all songs that were listened to completely(for all years considered)\n",
    "    df_track_partial = df[df['Play_Status'] == False] ## gives a list of all songs that were partially listened to(for all years considered)\n",
    "    y_complete = [] ## initializing as an empty list\n",
    "    y_partial = []  ## initializing as an empty list\n",
    "    for year in years:\n",
    "        count_tracks_complete = df_track_complete[df_track_complete['Play_Year']==year].shape[0] #gives the number of tracks completely listened to for a single year\n",
    "        count_tracks_partial = df_track_partial[df_track_partial['Play_Year']==year].shape[0] #gives the number of tracks partially listened to for a single year\n",
    "        percent_tracks_complete = 100 * (count_tracks_complete / df[df['Play_Year']== year].shape[0]) #gives a percentage of completely listened tracks in comparison to all the tracks listened to in that single year\n",
    "        percent_tracks_partial = 100 * (count_tracks_partial / df[df['Play_Year']== year].shape[0]) #gives a percentage of partially listened tracks in comparison to all the tracks listened to in that single year\n",
    "        y_complete.append(percent_tracks_complete) ## appends the percentage for completed tracks for each year \n",
    "        y_partial.append(percent_tracks_partial) ## appends the percentage for partial tracks for each year\n",
    "    return years, y_complete, y_partial\n",
    "\n",
    "years, y_complete, y_partial = build_partial_listening_plot(df_visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc49a958",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "''' Here, I pass the percentages of partially and completely listened tracks for each year and represent it visually \n",
    "using a stacked bar chart.\n",
    "'''\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(\n",
    "        name='Complete listening',\n",
    "        x = years,\n",
    "        y = y_complete,\n",
    "        marker=dict(\n",
    "            color='rgb(68,1,84)'\n",
    "        ),\n",
    "        hovertemplate=\n",
    "            \"Complete listening %{x}:  \" +\n",
    "            \"%{y:,.0f}%\" ),\n",
    "    go.Bar(\n",
    "        name='Partial listening',\n",
    "        x=years,\n",
    "        y=y_partial,\n",
    "        marker=dict(\n",
    "            color='rgb(220,227,25)'\n",
    "        ),\n",
    "        hovertemplate=\n",
    "            \"Partial listening %{x}:  \" +\n",
    "            \"%{y:,.0f} %\")\n",
    "])\n",
    "\n",
    "# Change the bar mode\n",
    "fig.update_layout(\n",
    "    title='Ratio of tracks skipped, versus listened to completely, per year',\n",
    "    barmode='stack',\n",
    "    yaxis=dict(title='Percentage of tracks')\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e481e519",
   "metadata": {},
   "source": [
    "#### In 2021, I tended to listen to the entire song more than in  2022, where I skipped songs after partial listening."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3768c56d",
   "metadata": {},
   "source": [
    "#### Finally, let's try to visualize a correlation between the fact that a song is in my library, and how my music's added to the library. The purpose here is to appreciate how relevant the suggestions are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a6b4fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plotting the repartition of track origin for all years and for tracks in the library\n",
    "\n",
    "labels = ['other', 'radio', 'search']\n",
    "values = df_visualization[(df_visualization['Library_Track']==True)&(df_visualization['Track_origin']!='library')]['Track_origin'].value_counts()\n",
    "\n",
    "fig = go.Figure(data=[go.Pie(labels=labels, \n",
    "                             values=values,\n",
    "                             textinfo='label+percent',\n",
    "                             hoverinfo='none')])\n",
    "fig.update_layout(\n",
    "    title='Distribution in percentage of how the library tracks were found, for all years',\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac52f8e",
   "metadata": {},
   "source": [
    "#### Surprisingly, I discover a lot of songs through stations, which are automatically generated and ongoing mixes based on a song, artist, or theme.¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556934ef",
   "metadata": {},
   "source": [
    "### Project 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3160f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_activity = pd.read_csv(\"/Users/khushgarg/Desktop/Apple Music - Recently Played Tracks.csv\")\n",
    "recent_activity_history = pd.read_csv(\"/Users/khushgarg/Desktop/Apple Music - Play History Daily Tracks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bac8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_activity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20beff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_activity_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4052b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
